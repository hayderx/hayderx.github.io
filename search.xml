<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ngx_http_proxy_module模块]]></title>
    <url>%2F2019%2F07%2F29%2FNginx%20Proxy%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[指令proxy_buffer_size 语法：proxy_buffer_size size 默认值：proxy_buffer_size 4k|8k； 上下文：http，server，location 设置缓冲区的大小为size，nginx从被代理的服务器读取响应时，使用该缓冲区保存响应的开始部分，这部分通常包含一个小小的响应头，该缓冲区大小默认为proxy_buffers指令设置的一块缓冲区的大小。 proxy_buffering 语法： proxy_buffering on |off 默认值： proxy_buffering on； 上下文： http，server，location 代理的时候，开启或关闭缓冲后端服务器的响应。 当开启缓冲时，nginx尽可能快地从被代理的服务器接收响应，再将它存入proxy_buffer_size和proxy_buffers指令设置的缓冲区中。如果响应无法整个纳入内存，那么其中一部分将存入磁盘上的临时文件proxy_max_temp_file_size和proxy_temp_file_write_size指令可以控制临时文件的写入。当关闭缓冲时，收到响应后，nginx立即将其同步传给客户端。nginx不会尝试从被代理的服务器读取整个请求，而是将proxy_buffer_size指令设定的大小作为一次读取的最大长度。 proxy_buffers 语法：proxy_buffers number size; 默认值：proxy_buffers 8 4k|8k; 上下文： http，server，location 为每个连接设置缓冲区的数量为number，每块缓冲区的大小为size。这些缓冲区用于保存从被代理的服务器读取的响应。每块缓冲区默认等于一个内存页的大小。这个值是4K还是8K，取决于平台。 proxu_busy_buffers_size 语法: proxy_busy_buffers_size size; 默认值: proxy_busy_buffers_size 8k|16k; 上下文: http, server, location 当开启缓冲响应的功能以后，在没有读到全部响应的情况下，写缓冲到达一定大小时，nginx一定会向客户端发送响应，直到缓冲小于此值。这条指令用来设置此值。 同时，剩余的缓冲区可以用于接收响应，如果需要，一部分内容将缓冲到临时文件。该大小默认是proxy_buffer_size和proxy_buffers指令设置单块缓冲大小的两倍。 proxy_cache 语法: proxy_cache zone | off; 默认值: proxy_cache off; 上下文: http, server, location 指定用于页面缓存的共享内存。同一块共享内存可以在多个地方使用。off参数可以屏蔽从上层配置继承的缓存功能。 proxy_cache_bypass 语法: proxy_cache_bypass string …; 默认值: — 上下文: http, server, location 定义nginx不从缓存取响应的条件。如果至少一个字符串条件非空而且非“0”，nginx就不会从缓存中去取响应： 12proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;proxy_cache_bypass $http_pragma $http_authorization; 本指令可和与proxy_no_cache一起使用。 proxy_cache_key语法: proxy_cache_key string;默认值: proxy_cache_key $scheme$proxy_host$request_uri;上下文: http, server, location定义如何生成缓存的键，比如 1proxy_cache_key "$host$request_uri $cookie_user"; 这条指令的默认值类似于下面字符串 1proxy_cache_key $scheme$proxy_host$uri$is_args$args; proxy_cache_valid 语法: proxy_cache_valid [code …] time; 默认值: — 上下文: http, server, location 为不同的响应状态码设置不同的缓存时间。比如，下面指令 12proxy_cache_valid 200 302 10m;proxy_cache_valid 404 1m; 设置状态码为200和302的响应的缓存时间为10分钟，状态码为404的响应的缓存时间为1分钟。 如果仅仅指定了time， 1proxy_cache_valid 5m; 那么只有状态码为200、300和302的响应会被缓存。 如果使用了any参数，那么就可以缓存任何响应： proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m;缓存参数也可以直接在响应头中设定。这种方式的优先级高于使用这条指令设置缓存时间。 “X-Accel-Expires”响应头可以以秒为单位设置响应的缓存时间，如果值为0，表示禁止缓存响应，如果值以@开始，表示自1970年1月1日以来的秒数，响应一直会被缓存到这个绝对时间点。 如果不含“X-Accel-Expires”响应头，缓存参数仍可能被“Expires”或者“Cache-Control”响应头设置。 如果响应头含有“Set-Cookie”，响应将不能被缓存。 这些头的处理过程可以使用指令proxy_ignore_headers忽略。 proxy_connect_timeout 语法: proxy_connect_timeout time; 默认值: proxy_connect_timeout 60s; 上下文: http, server, location 设置与后端服务器建立连接的超时时间。应该注意这个超时一般不可能大于75秒。 proxy_hide_header语法: proxy_hide_header field;默认值: —上下文: http, server, locationnginx默认不会将“Date”、“Server”、“X-Pad”，和“X-Accel-…”响应头发送给客户端。proxy_hide_header指令则可以设置额外的响应头，这些响应头也不会发送给客户端。相反的，如果希望允许传递某些响应头给客户端，可以使用proxy_pass_header指令。 proxy_http_version语法: proxy_http_version 1.0 | 1.1;默认值:proxy_http_version 1.0;上下文: http, server, location这个指令出现在版本 1.1.4. 设置代理使用的HTTP协议版本。默认使用的版本是1.0，而1.1版本则推荐在使用keepalive连接和 NTLM身份验证时一起使用。 proxy_ignore_client_abort 语法: proxy_ignore_client_abort on | off; 默认值: proxy_ignore_client_abort off; 上下文: http, server, location 决定当客户端在响应传输完成前就关闭连接时，nginx是否应关闭后端连接。 ### 语法: proxy_ignore_headers field …; 默认值: — 上下文: http, server, location 不处理后端服务器返回的指定响应头。下面的响应头可以被设置： “X-Accel-Redirect”，“X-Accel-Expires”，“X-Accel-Limit-Rate” (1.1.6)，“X-Accel-Buffering” (1.1.6)， “X-Accel-Charset” (1.1.6)，“Expires”，“Cache-Control”，和“Set-Cookie” (0.8.44)。 如果不被取消，这些头部的处理可能产生下面结果： “X-Accel-Expires”，“Expires”，“Cache-Control”，和“Set-Cookie” 设置响应缓存的参数； “X-Accel-Redirect”执行到指定URI的内部跳转； “X-Accel-Limit-Rate”设置响应到客户端的传输速率限制； “X-Accel-Buffering”启动或者关闭响应缓冲； “X-Accel-Charset”设置响应所需的字符集。proxy_intercept_errors 语法: proxy_intercept_errors on | off; 默认值: proxy_intercept_errors off; 上下文: http, server, location 当后端服务器的响应状态码大于等于400时，决定是否直接将响应发送给客户端，亦或将响应转发给nginx由error_page指令来处理。 proxy_max_temp_file_size 语法: proxy_max_temp_file_size size; 默认值: proxy_max_temp_file_size 1024m; 上下文: http, server, location 打开响应缓冲以后，如果整个响应不能存放在proxy_buffer_size和proxy_buffers指令设置的缓冲区内，部分响应可以存放在临时文件中。 这条指令可以设置临时文件的最大容量。而每次写入临时文件的数据量则由proxy_temp_file_write_size指令定义。将此值设置为0将禁止响应写入临时文件。 proxy_next_upstream 语法: proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_404 | off …; 默认值: proxy_next_upstream error timeout; 上下文: http, server, location 指定在何种情况下一个失败的请求应该被发送到下一台后端服务器： error: 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误； timeout: 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时； invalid_header: 后端服务器返回空响应或者非法响应头； http_500: 后端服务器返回的响应状态码为500； http_502: 后端服务器返回的响应状态码为502； http_503: 后端服务器返回的响应状态码为503； http_504: 后端服务器返回的响应状态码为504； http_404: 后端服务器返回的响应状态码为404； off: 停止将请求发送给下一台后端服务器。 需要理解一点的是，只有在没有向客户端发送任何数据以前，将请求转给下一台后端服务器才是可行的。也就是说，如果在传输响应到客户端时出现错误或者超时，这类错误是不可能恢复的。proxy_pass 语法: proxy_pass URL; 默认值: — 上下文: location, if in location, limit_except 设置后端服务器的协议和地址，还可以设置可选的URI以定义本地路径和后端服务器的映射关系。 这条指令可以设置的协议是“http”或者“https”，而地址既可以使用域名或者IP地址加端口（可选）的形式来定义： 1proxy_pass http://localhost:8000/uri/; 又可以使用UNIX域套接字路径来定义。该路径接在“unix”字符串后面，两端由冒号所包围，比如： 1proxy_pass http://unix:/tmp/backend.socket:/uri/; 如果解析一个域名得到多个地址，所有的地址都会以轮转的方式被使用。当然，也可以使用服务器组来定义地址。 请求URI按下面规则传送给后端服务器： 如果proxy_pass使用了URI，当传送请求到后端服务器时，规范化以后的请求路径与配置中的路径的匹配部分将被替换为指令中定义的URI： 123location /name/ &#123; proxy_pass http://127.0.0.1/remote/;&#125; 如果proxy_pass没有使用URI，传送到后端服务器的请求URI一般客户端发起的原始URI，如果nginx改变了请求URI，则传送的URI是nginx改变以后完整的规范化URI： 123location /some/path/ &#123; proxy_pass http://127.0.0.1;&#125; 在1.1.12版以前，如果proxy_pass没有使用URI，某些情况下，nginx改变URI以后，会错误地将原始URI而不是改变以后的URI发送到后端服务器。某些情况下，无法确定请求URI中应该被替换的部分： 使用正则表达式定义路径。这种情况下，指令不应该使用URI。 在需要代理的路径中，使用rewrite指令改变了URI，但仍使用相同配置处理请求(break)： 1234location /name/ &#123; rewrite /name/([^/]+) /users?name=$1 break; proxy_pass http://127.0.0.1;&#125; 这种情况下，本指令设置的URI会被忽略，改变后的URI将被发送给后端服务器。 后端服务器的地址，端口和URI中都可以使用变量： 1proxy_pass http://$host$uri; 甚至像这样： 1proxy_pass $request; 这种情况下，后端服务器的地址将会在定义的服务器组中查找。如果查找不到，nginx使用resolver来查找该地址。 proxy_pass_header 语法: proxy_pass_header field; 默认值: — 上下文: http, server, location 允许传送被屏蔽的后端服务器响应头到客户端。 proxy_read_timeout 语法: proxy_read_timeout time; 默认值: proxy_read_timeout 60s; 上下文: http, server, location 定义从后端服务器读取响应的超时。此超时是指相邻两次读操作之间的最长时间间隔，而不是整个响应传输完成的最长时间。如果后端服务器在超时时间段内没有传输任何数据，连接将被关闭。 proxy_redirect 语法: proxy_redirect default; proxy_redirect off; proxy_redirect redirect replacement; 默认值: proxy_redirect default; 上下文: http, server, location proxy_send_timeout 语法: proxy_send_timeout time; 默认值: proxy_send_timeout 60s; 上下文: http, server, location 定义向后端服务器传输请求的超时。此超时是指相邻两次写操作之间的最长时间间隔，而不是整个请求传输完成的最长时间。如果后端服务器在超时时间段内没有接收到任何数据，连接将被关闭。 proxy_set_header 语法: proxy_set_header field value; 默认值: proxy_set_header Host $proxy_host; proxy_set_header Connection close; 上下文: http, server, location 允许重新定义或者添加发往后端服务器的请求头。value可以包含文本、变量或者它们的组合。 当且仅当当前配置级别中没有定义proxy_set_header指令时，会从上面的级别继承配置。 默认情况下，只有两个请求头会被重新定义： 12proxy_set_header Host $proxy_host;proxy_set_header Connection close; 如果不想改变请求头“Host”的值，可以这样来设置： 1proxy_set_header Host $http_host; 但是，如果客户端请求头中没有携带这个头部，那么传递到后端服务器的请求也不含这个头部。 这种情况下，更好的方式是使用$host变量——它的值在请求包含“Host”请求头时为“Host”字段的值，在请求未携带“Host”请求头时为虚拟主机的主域名： 1proxy_set_header Host $host; 此外，服务器名可以和后端服务器的端口一起传送： 1proxy_set_header Host $host:$proxy_port; 如果某个请求头的值为空，那么这个请求头将不会传送给后端服务器： 1proxy_set_header Accept-Encoding ""; 内嵌变量ngx_http_proxy_module支持内嵌变量，可以用于在proxy_set_header指令中构造请求头： 12$proxy_host后端服务器的主机名和端口； 12proxy_port后端服务器的端口； 12$proxy_add_x_forwarded_for将$remote_addr变量值添加在客户端“X-Forwarded-For”请求头的后面，并以逗号分隔。 如果客户端请求未携带“X-Forwarded-For”请求头，$proxy_add_x_forwarded_for变量值将与$remote_addr变量相同。]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Saltstack]]></title>
    <url>%2F2019%2F07%2F29%2FSaltstack%2F</url>
    <content type="text"><![CDATA[Saltstack介绍特点 基于Python的C/S架构配置管理工具。 底层使用ZeroMQ消息队列pub/sub方式通信。 使用SSL证书签发的方式进行认证管理，传输采用AES加密。 服务架构在saltstack架构中服务端叫Master，客户端叫Minion。在Master和Minion段都是以守护进程的模式运行，一直监听配置文件里定义的ret_port(接受minion请求)和publish_port(发布消息)的端口。当Minion运行时会自动链接到配置文件里定义的Master地址ret_port端口进行连接认证。 运行方式- local： 本地运行 - Master/Minion：传统方式 - Syndic： 分布式 - Salt ssh组件介绍 组件 功能 Salt Master 用于将命令和配置发送到在受管系统上运行的Salt minion Salt Minion 从Salt master接收命令和配置 Execution Modules 实时监控，状态和库存；一次性命令和脚本；部署关键更新 Formulas (States) 系统配置的声明性或命令式表示 Grains Grains是有关底层受管系统的静态信息，包括操作系统，内存和许多其他系统属性。 Runners 在Salt master上执行的模块，用于执行支持任务。Salt runners报告作业状态，连接状态，从外部API读取数据，查询连接的Salt minions等。 Returners 将Salt minions返回的数据发送到另一个系统，例如数据库。Salt Returners可以在Salt minion或Salt master上运行。 Reactor 在SaltStack环境中发生事件时触发反应。 Salt SSH 在没有Salt minion的系统上通过SSH运行Salt命令。 SaltStack安装 ip 组件 192.168.111.43 salt salt-cloud salt-master salt-minion salt-ssh salt-syndic 192.168.111.45 salt-minion 配置yum源123rpm -ivh https://repo.saltstack.com/yum/redhat/salt-repo-latest-2.el7.noarch.rpm[root@Master ~]# yum -y install salt salt-cloud salt-master salt-minion salt-ssh salt-syndic[root@Minion ~]# yum -y install salt-minion 修改主控端配置文件，修改master地址和id1234[root@Master ~]# sed -i '/^#master:/a master: 192.168.111.43' /etc/salt/minion[root@Master ~]# sed -i '/^#id:/a id: 192.168.111.43' /etc/salt/minion[root@Minion ~]# sed -i '/^#master:/a master: 192.168.111.43' /etc/salt/minion[root@Minion ~]# sed -i '/^#id:/a id: 192.168.111.45' /etc/salt/minion 启动salt-master和salt-minion12[root@Master ~]# systemctl start salt-master &amp;&amp; systemctl start salt-minion &amp;&amp; systemctl enable salt-master &amp;&amp; systemctl enable salt-minion[root@Minion ~]# systemctl start salt-minion &amp;&amp; systemctl enable salt-minion 认证机制saltstack主控端是依靠openssl证书来与受控端主机认证通讯的，受控端启动后会发送给主控端一个公钥证书文件，在主控端用salt-key命令来管理证书。salt-minion与salt-master的认证过程： minion在第一次启动时，会在/etc/salt/pki/minion/下自动生成一对密钥，然后将公钥发给master master收到minion的公钥后，通过salt-key命令接受该公钥。此时master的/etc/salt/pki/master/minions目录将会存放以minion id命名的公钥，然后master就能对minion发送控制指令了 salt-key常用命令选项： -L 列出所有公钥信息 -a minion 接受指定minion等待认证的key -A 接受所有minion等待认证的key -r minion 拒绝指定minion等待认证的key -R 拒绝所有minion等待认证的key -f minion 显示指定key的指纹信息 -F 显示所有key的指纹信息 -d minion 删除指定minion的key -D 删除所有minion的key -y 自动回答yes查看并接受所有等待认证的key信息： 1234567[root@Master log]# salt-key -LAccepted Keys:Denied Keys:Unaccepted Keys:192.168.111.43192.168.111.45Rejected Keys: 123456789[root@Master log]# salt-key -yAThe following keys are going to be accepted:Unaccepted Keys:192.168.111.43192.168.111.45Key for minion 192.168.111.43 accepted.Key for minion 192.168.111.45 accepted.Key for minion Master accepted.Key for minion Minion accepted. 1234567[root@Master log]# salt-key -L Accepted Keys:192.168.111.43192.168.111.45Denied Keys:Unaccepted Keys:Rejected Keys: salt命令使用语法： salt [options] ‘‘ [arguments] 常用options --verion //查看saltstack版本号 --version-report //查看saltstack以及依赖包的版本号 -c CONFIG_DIR //指定配置文件目录(默认为/etc/salt) -t TIMEOUT //指定超时时间（默认5s） --async //异步执行 -v //verbose模式，详细显示执行过程 --username=USERNAME //指定外部认证用户名 --password=PASSWORD //指定外部认证密码 --log-file=LOG_FILE //指定日志记录文件常用target参数 -E //正则匹配 -L //列表匹配 -S //CIDR匹配网段 -G //grains匹配 --grain-pcre //grains加正则匹配 -N //组匹配 -R //范围匹配 -C //综合匹配（指定多个匹配） -I //pillar值匹配示例 12345[root@Master log]# salt -E "192*" test.ping192.168.111.43: True192.168.111.45: True 12345[root@Master log]# salt -L 192.168.111.43,192.168.111.45 test.ping192.168.111.43: True192.168.111.45: True 12345[root@Master log]# salt -S "192.168.111.0/24" test.ping192.168.111.45: True192.168.111.43: True 12345[root@Master log]# salt -G "os:centos" test.ping192.168.111.45: True192.168.111.43: True 123[root@Master log]# salt -N centos test.pingNode group centos unavailable in /etc/salt/master此处的centos是一个组名，需要在master配置文件中定义nodegroup参数，并需要知道monion的id信息才能将其定义至某个组里。 12345[root@Master log]# salt -C "G@os:centos or L@192.168.111.45" test.ping192.168.111.43: True192.168.111.45: True SaltStack配置管理SaltStack工程结构saltstack工程配置文件是由yaml格式编写，存放位置是由master配置文件中定义 12345[root@Master ~]# vim /etc/salt/masterfile_roots: base: - /srv/salt/base 配置一个apache实例在master上部署sls配置文件并执行12345678910111213[root@Master ~]# mkdir -p /srv/salt/&#123;base,test,dev,prod&#125;[root@Master ~]# cd /srv/salt/base/[root@Master ~]# vim apache.slsapache-install: pkg.installed: - names: - httpd - httpd-develapache-service: service.running: - name: httpd - enable: True 1[root@Master ~]# systemctl restart salt-master 执行状态描述文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[root@Master ~]# salt '192.168.111.45' state.sls apache saltenv=base192.168.111.45:---------- ID: apache-install Function: pkg.installed Name: httpd Result: True Comment: The following packages were installed/updated: httpd Started: 02:53:09.874053 Duration: 14615.114 ms Changes: ---------- httpd: ---------- new: 2.4.6-89.el7.centos old: httpd-tools: ---------- new: 2.4.6-89.el7.centos old:---------- ID: apache-install Function: pkg.installed Name: httpd-devel Result: True Comment: The following packages were installed/updated: httpd-devel Started: 02:53:24.575365 Duration: 4220.035 ms Changes: ---------- httpd-devel: ---------- new: 2.4.6-89.el7.centos old:---------- ID: apache-service Function: service.running Name: httpd Result: True Comment: Service httpd has been enabled, and is running Started: 02:53:30.413268 Duration: 306.401 ms Changes: ---------- httpd: TrueSummary for 192.168.111.45------------Succeeded: 3 (changed=3)Failed: 0------------Total states run: 3Total run time: 19.142 s top filetop file介绍直接通过命令执行sls文件时够自动化吗？答案是否定的，因为我们还要告诉某台主机要执行某个任务，自动化应该是我们让它干活时，它自己就知道哪台主机要干什么活，但是直接通过命令执行sls文件并不能达到这个目的，为了解决这个问题，top file 应运而生。top file就是一个入口，top file的文件名可通过在 Master的配置文件中搜索top.sls找出，且此文件必须在 base 环境中，默认情况下此文件必须叫top.sls。top file的作用就是告诉对应的主机要干什么活，比如让web服务器启动web服务，让数据库服务器安装mysql等等。 12345678910[root@Master srv]# tree /srv/salt//srv/salt/├── base│ ├── apache.sls│ └── top.sls├── dev├── prod└── test4 directories, 2 files 1234cat /srv/salt/base/top.slsbase: '192.168.111.45': - apache 使用高级状态来执行：注意：top file里面的’‘ 表示的是所有要执行状态的目标，而salt ‘‘ state.highstate的’*’表示通知所有机器干活，而是否要干活则是由top file来指定的。加上test=true参数执行则不会真正的执行操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@Master srv]# salt '*' state.highstate192.168.111.43:---------- ID: states Function: no.None Result: False Comment: No Top file or master_tops data matches found. Please see master log for details. Changes: Summary for 192.168.111.43------------Succeeded: 0Failed: 1------------Total states run: 1Total run time: 0.000 ms192.168.111.45:---------- ID: apache-install Function: pkg.installed Name: httpd Result: True Comment: All specified packages are already installed Started: 03:31:21.759843 Duration: 840.248 ms Changes: ---------- ID: apache-install Function: pkg.installed Name: httpd-devel Result: True Comment: All specified packages are already installed Started: 03:31:22.600423 Duration: 26.943 ms Changes: ---------- ID: apache-service Function: service.running Name: httpd Result: True Comment: The service httpd is already running Started: 03:31:22.628713 Duration: 66.155 ms Changes: Summary for 192.168.111.45------------Succeeded: 3Failed: 0------------Total states run: 3Total run time: 933.346 msERROR: Minions returned with non-zero exit code SaltStack数据系统SaltStack有两大数据系统： Grains Pillar SaltStack组件之GrainsGrains是saltstack一个非常重要的组件之一，存放着minion启动时收集到的信息，记录minion的一些静态信息，可以简单理解为记录每台minion的一些常用属性，比如主机名，CPU，内存，磁盘，网络信息等。可以通过grains.items查看某台minion的所有Grains信息。 信息实例查询列出所有grains的key和value 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299[root@Master log]# salt "192.168.111.45" grains.items192.168.111.45: ---------- SSDs: biosreleasedate: 04/05/2016 biosversion: 6.00 cpu_flags: - fpu - vme - de - pse - tsc - msr - pae - mce - cx8 - apic - sep - mtrr - pge - mca - cmov - pat - pse36 - clflush - dts - mmx - fxsr - sse - sse2 - ss - syscall - nx - pdpe1gb - rdtscp - lm - constant_tsc - arch_perfmon - pebs - bts - nopl - xtopology - tsc_reliable - nonstop_tsc - eagerfpu - pni - pclmulqdq - ssse3 - fma - cx16 - pcid - sse4_1 - sse4_2 - x2apic - movbe - popcnt - tsc_deadline_timer - aes - xsave - avx - f16c - rdrand - hypervisor - lahf_lm - abm - 3dnowprefetch - fsgsbase - tsc_adjust - bmi1 - hle - avx2 - smep - bmi2 - invpcid - rtm - rdseed - adx - smap - xsaveopt - ibpb - ibrs - stibp - arat - spec_ctrl - intel_stibp - arch_capabilities cpu_model: Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz cpuarch: x86_64 disks: - sda - sr0 - dm-0 - dm-1 dns: ---------- domain: ip4_nameservers: - 192.168.99.66 - 202.101.172.35 - 202.101.172.46 ip6_nameservers: nameservers: - 192.168.99.66 - 202.101.172.35 - 202.101.172.46 options: search: sortlist: domain: fqdn: Minion fqdn_ip4: - 192.168.111.45 fqdn_ip6: - fe80::a140:9424:7f60:f266 fqdns: gid: 0 gpus: |_ ---------- model: SVGA II Adapter vendor: vmware groupname: root host: Minion hwaddr_interfaces: ---------- ens192: 00:0c:29:e2:fd:39 lo: 00:00:00:00:00:00 id: 192.168.111.45 init: systemd ip4_gw: 192.168.111.254 ip4_interfaces: ---------- ens192: - 192.168.111.45 lo: - 127.0.0.1 ip6_gw: False ip6_interfaces: ---------- ens192: - fe80::a140:9424:7f60:f266 lo: - ::1 ip_gw: True ip_interfaces: ---------- ens192: - 192.168.111.45 - fe80::a140:9424:7f60:f266 lo: - 127.0.0.1 - ::1 ipv4: - 127.0.0.1 - 192.168.111.45 ipv6: - ::1 - fe80::a140:9424:7f60:f266 kernel: Linux kernelrelease: 3.10.0-862.el7.x86_64 kernelversion: #1 SMP Fri Apr 20 16:44:24 UTC 2018 locale_info: ---------- defaultencoding: UTF-8 defaultlanguage: en_US detectedencoding: UTF-8 localhost: Minion lsb_distrib_codename: CentOS Linux 7 (Core) lsb_distrib_id: CentOS Linux machine_id: 10fb57545175412dbbdead43d1270cd7 manufacturer: VMware, Inc. master: 192.168.111.43 mdadm: mem_total: 992 nodename: Minion num_cpus: 1 num_gpus: 1 os: CentOS os_family: RedHat osarch: x86_64 oscodename: CentOS Linux 7 (Core) osfinger: CentOS Linux-7 osfullname: CentOS Linux osmajorrelease: 7 osrelease: 7.5.1804 osrelease_info: - 7 - 5 - 1804 path: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin pid: 2558 productname: VMware Virtual Platform ps: ps -efHww pythonexecutable: /usr/bin/python pythonpath: - /usr/bin - /usr/lib64/python27.zip - /usr/lib64/python2.7 - /usr/lib64/python2.7/plat-linux2 - /usr/lib64/python2.7/lib-tk - /usr/lib64/python2.7/lib-old - /usr/lib64/python2.7/lib-dynload - /usr/lib64/python2.7/site-packages - /usr/lib/python2.7/site-packages pythonversion: - 2 - 7 - 5 - final - 0 saltpath: /usr/lib/python2.7/site-packages/salt saltversion: 2019.2.0 saltversioninfo: - 2019 - 2 - 0 - 0 selinux: ---------- enabled: True enforced: Permissive serialnumber: VMware-56 4d 71 53 1d bc 6a 67-13 b4 e3 88 5f e2 fd 39 server_id: 1370726209 shell: /bin/sh swap_total: 1639 systemd: ---------- features: +PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN version: 219 uid: 0 username: root uuid: 53714d56-bc1d-676a-13b4-e3885fe2fd39 virtual: VMware zfs_feature_flags: False zfs_support: False zmqversion: 4.1.4 只查询所有的grains的key 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[root@Master log]# salt "192.168.111.45" grains.ls192.168.111.45: - SSDs - biosreleasedate - biosversion - cpu_flags - cpu_model - cpuarch - disks - dns - domain - fqdn - fqdn_ip4 - fqdn_ip6 - fqdns - gid - gpus - groupname - host - hwaddr_interfaces - id - init - ip4_gw - ip4_interfaces - ip6_gw - ip6_interfaces - ip_gw - ip_interfaces - ipv4 - ipv6 - kernel - kernelrelease - kernelversion - locale_info - localhost - lsb_distrib_codename - lsb_distrib_id - machine_id - manufacturer - master - mdadm - mem_total - nodename - num_cpus - num_gpus - os - os_family - osarch - oscodename - osfinger - osfullname - osmajorrelease - osrelease - osrelease_info - path - pid - productname - ps - pythonexecutable - pythonpath - pythonversion - saltpath - saltversion - saltversioninfo - selinux - serialnumber - server_id - shell - swap_total - systemd - uid - username - uuid - virtual - zfs_feature_flags - zfs_support - zmqversion 查询某个key的值 123[root@Master log]# salt "192.168.111.45" grains.get fqdn_ip4192.168.111.45: - 192.168.111.45 1234567[root@Master log]# salt "192.168.111.45" grains.get ip4_interfaces192.168.111.45: ---------- ens192: - 192.168.111.45 lo: - 127.0.0.1 123[root@Master log]# salt "192.168.111.45" grains.get ip4_interfaces:ens192192.168.111.45: - 192.168.111.45 目标匹配实例用Grains来匹配minion： 123456在所有centos系统执行命令：[root@Master srv]# salt -G 'os:centos' cmd.run 'uptime'192.168.111.43: 03:38:03 up 4:30, 2 users, load average: 0.01, 0.06, 0.12192.168.111.45: 03:38:03 up 4:30, 2 users, load average: 0.00, 0.01, 0.05 自定义grains item 方式一：修改minion配置文件 1234567891011[root@Master ~]# vim /etc/salt/miniongrains: roles: - webserver - memcache[root@Master ~]# systemctl restart salt-minion[root@Master ~]# salt '*' grains.get roles192.168.111.45:192.168.111.43: - webserver - memcache 方式二: 自定义grains文件（生产环境推荐使用） 12345678910[root@Master ~]# vim /etc/salt/grainscloud: - openstack - kubernetes[root@Master ~]# systemctl restart salt-minion[root@Master ~]# salt '*' grains.get cloud192.168.111.45:192.168.111.43: - openstack - kubernetes 不重启minion使自定义生效： 1234567891011121314[root@Master salt]# salt '*' grains.get cloud192.168.111.43: - openstack - kubernetes192.168.111.45:[root@Master salt]# salt '*' saltutil.sync_grains192.168.111.43:192.168.111.45:[root@Master salt]# salt '*' grains.get cloud 192.168.111.43: - openstack - kubernetes - zabbix192.168.111.45: SaltStack组件之PillarPillar使SaltStack数据管理中心，经常配置states在大规模的配置管理工作中使用它。Pillar在SaltStack中主要的作用就是存储和定义配置管理中需要的一些数据，比如软件版本号，用户名密码等信息，它的定义存储格式和Grains类似，都是YAML格式。 Pillar的特点 可以给指定的minion定义它需要的数据 只有指定的人才能看到定义的数据 在master配置文件里设置 master配置文件定义默认Base环境下Pillar的工作目录是/srv/pillar目录下。默认salt ‘*’ pillar.items是没有任何信息的，需要在master配置文件中将pillar_opts: False 改为True。 Pillar自定义数据 打开master配置文件中的pillar_roots配置 1234567891011121314151617pillar_roots: base: - /srv/pillar/base prod: - /srv/pillar/prod[root@Master ~]# systemctl restart salt-master[root@Master ~]# mkdir -p /srv/pillar/&#123;base,prod&#125;[root@Master ~]# tree /srv/pillar//srv/pillar/├── base└── prod[root@Master ~]# vim /srv/pillar/base/apache.sls&#123;% if grains['os'] == 'CentOS' %&#125;apache: httpd&#123;% elif grains['os'] == 'Debian' %&#125;apache: apache2&#123;% endif %&#125; 定义top file入口文件 1234[root@master ~]# vim /srv/pillar/base/top.slsbase: '192.168.111.43': - apache 这个top.sls文件的意思表示的是192.168.111.43这台主机的base环境能够访问到apache这个pillar 12345678910[root@master ~]# salt '*' pillar.items192.168.111.43: ---------- apache: httpd192.168.111.45: ----------``` - 在salt下修改apache的状态文件，引用pillar的数据 [root@master ~]# vim /srv/salt/base/web/apache/apache.slsapache-install: pkg.installed: - name: apache-service: service.running: - name: - enable: True 12- 执行高级状态文件 [root@master ~]# salt ‘192.168.111.43’ state.highstate]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
        <tag>saltstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1hexo new "My New Post" More info: Writing Run server1hexo server More info: Server Generate static files1hexo generate More info: Generating Deploy to remote sites1hexo deploy More info: Deployment]]></content>
  </entry>
</search>
