<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[helm部署harbor仓库]]></title>
    <url>%2F2021%2F01%2F29%2Fhelm%E9%83%A8%E7%BD%B2harbor%2F</url>
    <content type="text"><![CDATA[环境介绍| kubernetes | 1.19.0 || helm | v3.4.2 || harbor | 2.1.3 | 角色 IP master 192.168.0.103 192.168.0.105 192.168.0.106 node 192.168.0.107 192.168.0.108 nfs-server 192.168.0.110 helm 192.168.0.103 部署过程证书文件准备阿里云申请免费ssl证书，下载Nginx证书，将.pem 重命名为tls.crt，.key 重命名为tls.key。 安装helm下载对应的helm文件 1234wget https://get.helm.sh/helm-v3.4.2-linux-amd64.tar.gztar -zxf helm-v3.4.2-linux-amd64.tar.gz &amp;&amp; cd linux-amd64 &amp;&amp; mv helm /usr/local/bin/[root@k8s-master01 opt]# helm versionversion.BuildInfo&#123;Version:"v3.4.2", GitCommit:"23dd3af5e19a02d4f4baa5b2f242645a1a3af629", GitTreeState:"clean", GoVersion:"go1.14.13"&#125; helm命令介绍具体使用方法见官方doc https://helm.sh/docs/helm/ 创建harbor持久化存储卷正常情况下我们需要先创建好PV,再根据PV创建PVC,但是如果我们需要大量的PVC,那么维护起来就非常困难。kubernetes提供了一种自动创建PV的机制StorageClass。支持NFS/CEPH等。harbor各服务需要持久化部署，可以通过yaml文件手动创建各服务的pv，pvc。这里我们使用nfs-client-provisioner来创建动态pvnfs-client-provisioner: 为托管的 pod 提供了动态存储服务，pod 创建者无需关心数据以何种方式存在哪里，只需要提出需要多大空间的申请即可。根据PVC的需求自动创建符合要求的PV。github地址： https://github.com/kubernetes-retired/external-storage/tree/master/nfs 在192.168.0.110部署nfs-server 1yum install -y nfs-utils rpcbind 创建nfs共享目录 1234567891011mkdir -p /data/harbor &amp;&amp; chmod 777 -R /data/harborvim /etc/exports ###创建exports文件/data/harbor *(rw,no_root_squash,sync)exportfs -a ### 全部挂载systemctl enable rpcbindsystemctl enable nfs-serversystemctl start rpcbindsystemctl start nfs-server 在每个node节点安装nfs客户端程序 1234yum -y install nfs-utils[root@k8s-node01 ~]# showmount -e 192.168.0.110Export list for 192.168.0.110:/data/harbor * 部署nfs-client-provisioner 创建RBAC 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[root@k8s-master01 nfs-provisioner]# cat rbac.yaml apiVersion: v1kind: ServiceAccountmetadata: name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: nfs-client-provisioner-runnerrules: - apiGroups: [""] resources: ["persistentvolumes"] verbs: ["get", "list", "watch", "create", "delete"] - apiGroups: [""] resources: ["persistentvolumeclaims"] verbs: ["get", "list", "watch", "update"] - apiGroups: ["storage.k8s.io"] resources: ["storageclasses"] verbs: ["get", "list", "watch"] - apiGroups: [""] resources: ["events"] verbs: ["create", "update", "patch"]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-client-provisionersubjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: defaultroleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: defaultrules: - apiGroups: [""] resources: ["endpoints"] verbs: ["get", "list", "watch", "create", "update", "patch"]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: defaultsubjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: defaultroleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io 1kubectl apply -f rbac.yaml 创建deployment 12345678910111213141516171819202122232425262728293031323334353637383940[root@k8s-master01 nfs-provisioner]# cat deploy.yaml apiVersion: apps/v1kind: Deploymentmetadata: name: nfs-client-provisioner labels: app: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: defaultspec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: quay.io/external_storage/nfs-client-provisioner:latest volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: fuseim.pri/ifs ##该值需要和后面StorageClass中provisioner的值一致， - name: NFS_SERVER value: 192.168.0.110 ### nfs-server地址 - name: NFS_PATH value: /data/harbor ### nfs共享目录 volumes: - name: nfs-client-root nfs: server: 192.168.0.110 ### nfs-server地址 path: /data/harbor ### nfs共享目录 1kubectl apply -f deploy.yaml 创建StorageClass 12345678[root@k8s-master01 nfs-provisioner]# cat sc.yaml apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: harbor-nfs-storageprovisioner: fuseim.pri/ifs # or choose another name, must match deployment's env PROVISIONER_NAME'parameters: archiveOnDelete: "false" 1kubectl apply -f sc.yaml 123[root@k8s-master01 nfs-provisioner]# kubectl get scNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGEharbor-nfs-storage fuseim.pri/ifs Delete Immediate false 66m helm添加harbor repo仓库1234[root@k8s-master01 data]# helm repo add harbor https://helm.goharbor.io[root@k8s-master01 data]# helm repo listNAME URL harbor https://helm.goharbor.io helm 拉取harbor charts123456789101112131415161718[root@k8s-master01 data]# helm search repo harborNAME CHART VERSION APP VERSION DESCRIPTION harbor/harbor 1.5.3 2.1.3 An open source trusted cloud native registry th...[root@k8s-master01 data]# helm pull harbor/harbor[root@k8s-master01 data]# lsharbor-1.5.3.tgz[root@k8s-master01 data]# tar -zxf harbor-1.5.3.tgz [root@k8s-master01 data]# tree -L 1 harborharbor├── cert├── Chart.yaml├── conf├── LICENSE├── README.md├── templates└── values.yaml3 directories, 4 files 证书上传将之前制备好的crt和key文件覆盖到harbor下的cert目录。 创建secret[root@k8s-master01 harbor]# kubectl create secret tls harbor-tls –cert=cert/tls.crt –key=cert/tls.key 修改values.yaml需要修改的行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859expose: type: ingress tls: enabled: true certSource: secret auto: commonName: "" secret: secretName: "harbor-tls" ### notarySecretName: "harbor-tls" ### ingress: hosts: core: harbor.hayder.top ### notary: notary.hayder.top ### externalURL: https://harbor.hayder.top ###persistence: enabled: true resourcePolicy: "keep" persistentVolumeClaim: registry: existingClaim: "" storageClass: "harbor-nfs-storage" ### subPath: "" accessMode: ReadWriteOnce size: 5Gi chartmuseum: existingClaim: "" storageClass: "harbor-nfs-storage" ### subPath: "" accessMode: ReadWriteOnce size: 5Gi jobservice: existingClaim: "" storageClass: "harbor-nfs-storage" ### subPath: "" accessMode: ReadWriteOnce size: 1Gi database: existingClaim: "" storageClass: "harbor-nfs-storage" ### subPath: "" accessMode: ReadWriteOnce size: 1Gi redis: existingClaim: "" storageClass: "harbor-nfs-storage" ### subPath: "" accessMode: ReadWriteOnce size: 1Gi trivy: existingClaim: "" storageClass: "harbor-nfs-storage" ### subPath: "" accessMode: ReadWriteOnce size: 5Gi 安装harbor1234567891011[root@k8s-master01 harbor]# helm install harbor2 .NAME: harbor2LAST DEPLOYED: Fri Jan 29 04:40:04 2021NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: NoneNOTES:Please wait for several minutes for Harbor deployment to complete.Then you should be able to visit the Harbor portal at https://harbor.hayder.topFor more details, please visit https://github.com/goharbor/harbor 1234567891011121314[root@k8s-master01 harbor]# kubectl get pods NAME READY STATUS RESTARTS AGEharbor2-harbor-chartmuseum-67846d485b-b6kxh 1/1 Running 0 99sharbor2-harbor-clair-84c485fdb9-ljx6f 2/2 Running 3 100sharbor2-harbor-core-7c497685d-zc5bd 1/1 Running 0 99sharbor2-harbor-database-0 1/1 Running 0 99sharbor2-harbor-jobservice-6f5c9cdcdb-8bp2b 1/1 Running 0 99sharbor2-harbor-notary-server-6d6bd55df8-6jdcr 1/1 Running 1 100sharbor2-harbor-notary-signer-784c986f9f-rwzbr 1/1 Running 0 100sharbor2-harbor-portal-5b94b6f896-jkn5v 1/1 Running 0 100sharbor2-harbor-redis-0 1/1 Running 0 99sharbor2-harbor-registry-85dd67cb96-62sqz 2/2 Running 0 100sharbor2-harbor-trivy-0 1/1 Running 0 99snfs-client-provisioner-6c4944c4b-jw9mv 1/1 Running 0 8m6s 访问测试访问https://harbor.hayder.top 默认用户名密码： admin/Admin12345]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes部署traefik2]]></title>
    <url>%2F2021%2F01%2F27%2Ftraefik%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[环境介绍 角色 IP master 192.168.0.103 192.168.0.105 node 192.168.0.106 192.168.0.107 192.168.0.108 nginx+keepalived 192.168.0.109 192.168.0.110 部署方式介绍traefik有多种部署方式，当前我们使用daemonset方式部署 deployment daemonset helmdaemonset 能确定有哪些node在运行traefik，所以可以确定的知道后端ip，但是不能方便的伸缩。deployment 可以更方便的伸缩，但是不能确定有哪些node在运行traefik所以不能确定的知道后端ip。 部署过程创建crd文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@k8s-master01 traefik]# vim crd.yaml## IngressRouteapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: ingressroutes.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: IngressRoute plural: ingressroutes singular: ingressroute---## IngressRouteTCPapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: ingressroutetcps.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: IngressRouteTCP plural: ingressroutetcps singular: ingressroutetcp---## MiddlewareapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: middlewares.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: Middleware plural: middlewares singular: middleware---## TLSOptionapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: tlsoptions.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: TLSOption plural: tlsoptions singular: tlsoption---## TraefikServiceapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: traefikservices.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: TraefikService plural: traefikservices singular: traefikservice 1[root@k8s-master01 traefik]# kubectl apply -f crd.yaml 创建RBAC123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126[root@k8s-master01 traefik]# vim rbac.yaml## IngressRouteapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: ingressroutes.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: IngressRoute plural: ingressroutes singular: ingressroute---## IngressRouteTCPapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: ingressroutetcps.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: IngressRouteTCP plural: ingressroutetcps singular: ingressroutetcp---## MiddlewareapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: middlewares.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: Middleware plural: middlewares singular: middleware---## TLSOptionapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: tlsoptions.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: TLSOption plural: tlsoptions singular: tlsoption---## TraefikServiceapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: traefikservices.traefik.containo.usspec: scope: Namespaced group: traefik.containo.us version: v1alpha1 names: kind: TraefikService plural: traefikservices singular: traefikservice[root@k8s-master01 traefik]# kubectl apply -f crd.yaml ^C[root@k8s-master01 traefik]# vim rbac.yaml ^C[root@k8s-master01 traefik]# cat rbac.yaml ## ServiceAccountapiVersion: v1kind: ServiceAccountmetadata: namespace: kube-system name: traefik-ingress-controller---## ClusterRolekind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: traefik-ingress-controller namespace: kube-systemrules: - apiGroups: [""] resources: ["services","endpoints","secrets"] verbs: ["get","list","watch"] - apiGroups: ["extensions"] resources: ["ingresses"] verbs: ["get","list","watch"] - apiGroups: ["extensions"] resources: ["ingresses/status"] verbs: ["update"] - apiGroups: ["traefik.containo.us"] resources: ["middlewares"] verbs: ["get","list","watch"] - apiGroups: ["traefik.containo.us"] resources: ["ingressroutes"] verbs: ["get","list","watch"] - apiGroups: ["traefik.containo.us"] resources: ["ingressroutetcps"] verbs: ["get","list","watch"] - apiGroups: ["traefik.containo.us"] resources: ["tlsoptions"] verbs: ["get","list","watch"] - apiGroups: ["traefik.containo.us"] resources: ["traefikservices"] verbs: ["get","list","watch"]---## ClusterRoleBindingkind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: traefik-ingress-controllerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: traefik-ingress-controllersubjects: - kind: ServiceAccount name: traefik-ingress-controller namespace: kube-system 1[root@k8s-master01 traefik]# kubectl apply -f rbac.yaml 创建configmap123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@k8s-master01 traefik]# vim configmap.yaml kind: ConfigMapapiVersion: v1metadata: name: traefik-config namespace: kube-systemdata: traefik.yaml: |- ping: "" ## 启用 Ping serversTransport: insecureSkipVerify: true ## Traefik 忽略验证代理服务的 TLS 证书 api: insecure: true ## 允许 HTTP 方式访问 API dashboard: true ## 启用 Dashboard debug: false ## 启用 Debug 调试模式 metrics: prometheus: "" ## 配置 Prometheus 监控指标数据，并使用默认配置 entryPoints: web: address: ":80" ## 配置 80 端口，并设置入口名称为 web websecure: address: ":443" ## 配置 443 端口，并设置入口名称为 websecure providers: kubernetesCRD: "" ## 启用 Kubernetes CRD 方式来配置路由规则 kubernetesIngress: "" ## 启动 Kubernetes Ingress 方式来配置路由规则 log: filePath: "" ## 设置调试日志文件存储路径，如果为空则输出到控制台 level: error ## 设置调试日志级别 format: json ## 设置调试日志格式 accessLog: filePath: "" ## 设置访问日志文件存储路径，如果为空则输出到控制台 format: json ## 设置访问调试日志格式 bufferingSize: 0 ## 设置访问日志缓存行数 filters: #statusCodes: ["200"] ## 设置只保留指定状态码范围内的访问日志 retryAttempts: true ## 设置代理访问重试失败时，保留访问日志 minDuration: 20 ## 设置保留请求时间超过指定持续时间的访问日志 fields: ## 设置访问日志中的字段是否保留（keep 保留、drop 不保留） defaultMode: keep ## 设置默认保留访问日志字段 names: ## 针对访问日志特别字段特别配置保留模式 ClientUsername: drop headers: ## 设置 Header 中字段是否保留 defaultMode: keep ## 设置默认保留 Header 中字段 names: ## 针对 Header 中特别字段特别配置保留模式 User-Agent: redact Authorization: drop Content-Type: keep 12[root@k8s-master01 traefik]# kubectl apply -f configmap.yaml 部署traefik1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980[root@k8s-master01 traefik]# vim deploy.yamlapiVersion: v1kind: ServiceAccountmetadata: name: traefik-ingress-controller namespace: kube-system---apiVersion: v1kind: Servicemetadata: name: traefik namespace: kube-systemspec: ports: - name: web port: 80 - name: websecure port: 443 - name: admin port: 8080 selector: app: traefik---apiVersion: apps/v1kind: DaemonSetmetadata: name: traefik-ingress-controller namespace: kube-system labels: app: traefikspec: selector: matchLabels: app: traefik template: metadata: name: traefik labels: app: traefik spec: serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 1 containers: - image: traefik:v2.1.2 name: traefik-ingress-lb ports: - name: web containerPort: 80 hostPort: 80 ## 将容器端口绑定所在服务器的 80 端口 - name: websecure containerPort: 443 hostPort: 443 ## 将容器端口绑定所在服务器的 443 端口 - name: admin containerPort: 8080 ## Traefik Dashboard 端口 resources: limits: cpu: 2000m memory: 1024Mi requests: cpu: 1000m memory: 1024Mi securityContext: capabilities: drop: - ALL add: - NET_BIND_SERVICE args: - --configfile=/config/traefik.yaml volumeMounts: - mountPath: "/config" name: "config" volumes: - name: config configMap: name: traefik-config tolerations: ## 设置容忍所有污点，防止节点被设置污点 - operator: "Exists" 12[root@k8s-master01 traefik]# kubectl apply -f deploy.yaml 验证我们使用traefik后台来验证 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798[root@k8s-master01 traefik]# vim dashboard-route.yamlapiVersion: v1kind: ServiceAccountmetadata: name: traefik-ingress-controller namespace: kube-system---apiVersion: v1kind: Servicemetadata: name: traefik namespace: kube-systemspec: ports: - name: web port: 80 - name: websecure port: 443 - name: admin port: 8080 selector: app: traefik---apiVersion: apps/v1kind: DaemonSetmetadata: name: traefik-ingress-controller namespace: kube-system labels: app: traefikspec: selector: matchLabels: app: traefik template: metadata: name: traefik labels: app: traefik spec: serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 1 containers: - image: traefik:v2.1.2 name: traefik-ingress-lb ports: - name: web containerPort: 80 hostPort: 80 ## 将容器端口绑定所在服务器的 80 端口 - name: websecure containerPort: 443 hostPort: 443 ## 将容器端口绑定所在服务器的 443 端口 - name: admin containerPort: 8080 ## Traefik Dashboard 端口 resources: limits: cpu: 2000m memory: 1024Mi requests: cpu: 1000m memory: 1024Mi securityContext: capabilities: drop: - ALL add: - NET_BIND_SERVICE args: - --configfile=/config/traefik.yaml volumeMounts: - mountPath: "/config" name: "config" volumes: - name: config configMap: name: traefik-config tolerations: ## 设置容忍所有污点，防止节点被设置污点 - operator: "Exists"[root@k8s-master01 traefik]# kubectl apply -f deploy.yaml ^C[root@k8s-master01 traefik]# lsconfigmap.yaml crd.yaml dashboard-route.yaml deploy.yaml rbac.yaml[root@k8s-master01 traefik]# vim dashboard-route.yaml ^C[root@k8s-master01 traefik]# cat dashboard-route.yaml apiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata: name: traefik-dashboard-route namespace: kube-systemspec: entryPoints: - web routes: - match: Host(`traefik.hayder.com`) kind: Rule services: - name: traefik port: 8080 12345[root@k8s-master01 traefik]# kubectl apply -f dashboard-route.yaml[root@k8s-master01 traefik]# kubectl get ingressroute -n kube-systemNAME AGEtraefik-dashboard-route 41m[root@k8s-master01 traefik]# 在hosts文件添加解析 192.168.0.107 traefik.hayder.com浏览器访问http://traefik.hayder.com]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python web框架Sanic之路由]]></title>
    <url>%2F2020%2F05%2F28%2FPython%20web%E6%A1%86%E6%9E%B6Sanic%E4%B9%8B%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[路由sanic中可以用app.route装饰器来定义路由，Route允许用户为不同的URL指定处理程序。 1234567891011from sanic import Sanicfrom sanic.response import jsonapp = Sanic("hayder")@app.route("/")async def test(request): return json(&#123;"hello": "world"&#125;)if __name__ == "__main__": app.run(host="0.0.0.0", port=8000) 如上demo，当访问服务端:8000/时，将请求url与app.route装饰器定义的路由进行匹配，然后执行相应的处理函数并返回json对象。 请求参数Sanic 带有支持请求参数的基本路由请求参数将作为关键字参数传递给路由对应的程序处理。 1234567from sanic.response import textfrom sanic import Sanicapp = Sanic(__name__)@app.route('/tag/&lt;tag&gt;')async def tag_handler(request, tag): return text('Tag - &#123;&#125;'.format(tag)) 如果要指定参数类型，需要加上&lt;&gt;，并指定参数的type(:type)，如果参数与指定的类型不匹配，将抛出NotFound异常，404错误。支持的类型如下： 字符串string 整形int number path uuid 1234567891011121314151617181920212223242526272829303132333435from sanic.response import textfrom sanic import Sanicapp = Sanic(__name__)@app.route('/string/&lt;string_arg:string&gt;')async def string_handler(request, string_arg): return text('String - &#123;&#125;'.format(string_arg))@app.route('/int/&lt;integer_arg:int&gt;')async def integer_handler(request, integer_arg): return text('Integer - &#123;&#125;'.format(integer_arg))@app.route('/number/&lt;number_arg:number&gt;')async def number_handler(request, number_arg): return text('Number - &#123;&#125;'.format(number_arg))@app.route('/alpha/&lt;alpha_arg:alpha&gt;')async def number_handler(request, alpha_arg): return text('Alpha - &#123;&#125;'.format(alpha_arg))@app.route('/path/&lt;path_arg:path&gt;')async def number_handler(request, path_arg): return text('Path - &#123;&#125;'.format(path_arg))@app.route('/uuid/&lt;uuid_arg:uuid&gt;')async def number_handler(request, uuid_arg): return text('Uuid - &#123;&#125;'.format(uuid_arg))@app.route('/person/&lt;name:[A-z]+&gt;')async def person_handler(request, name): return text('Person - &#123;&#125;'.format(name))@app.route('/folder/&lt;folder_id:[A-z0-9]&#123;0,4&#125;&gt;')async def folder_handler(request, folder_id): return text('Folder - &#123;&#125;'.format(folder_id)) HTTP请求类型默认情况下，URL上定义的路由仅可用于该URL的GET请求，但是@app.route装饰器接受可选参数method。 123456789101112131415from sanic.response import textfrom sanic import Sanicapp = Sanic(__name__)@app.route('/post', methods=['POST'])#也可以写成下面这种方式#@app.post('/post')async def post_handler(request): return text('POST request - &#123;&#125;'.format(request.json))@app.route('/get', methods=['GET'])#也可以写成下面这种方式#@app.get('/get')async def get_handler(request): return text('GET request - &#123;&#125;'.format(request.args)) 对上面代码测试访问， 12345678910111213import requestsimport jsonurl = "http://127.0.0.1:8000/post"req1 = requests.post(url="http://127.0.0.1:8000/post",data=json.dumps(&#123;"a":"b"&#125;))req2 = requests.get(url="http://127.0.0.1:8000/get?a=1")print(req1.text)print(req2.text)OutPut：POST request - &#123;'a': 'b'&#125;GET request - &#123;'a': ['1']&#125; 还有一个可选的参数host，对路由进行限制 123456789#如果host header匹配到example.com，将会使用下面的限制路由@app.route('/get', methods=['GET'], host='example.com')async def get_handler(request): return text('GET request - &#123;&#125;'.format(request.args))# 如果host header没有匹配到 example.com, 将会使用下面的默认路由@app.route('/get', methods=['GET'])async def get_handler(request): return text('GET request in default - &#123;&#125;'.format(request.args)) add_route()方法@app.route方法实际上只是app.add_route()的语法糖。实际等于 123456789from sanic.response import textfrom sanic import Sanicapp = Sanic(__name__)async def person_handler2(request, name): return text('Person - &#123;&#125;'.format(name)) app.add_route(person_handler2, '/person/&lt;name:[A-z]&gt;', methods=['GET']) url_forSanic提供了url_for方法，用于根据处理程序方法名称生成URL，如果要避免将url路径硬编码到应用程序中，这将很有用。 123456789101112131415from sanic.response import redirectfrom sanic import Sanicapp = Sanic(__name__)@app.route('/')async def index(request): # generate a URL for the endpoint `post_handler` url = app.url_for('post_handler', post_id=5) # the URL is `/posts/5`, redirect to it return redirect(url)@app.route('/posts/&lt;post_id&gt;')async def post_handler(request, post_id): return text('Post - &#123;&#125;'.format(post_id)) 请求/时会跳转到/posts/5 传递给url_for的不是请求参数的关键字参数将包含在URL的查询字符串中。1url = app.url_for('post_handler', post_id=5, arg_one='one', arg_two='two') 上面代码在请求访问/时，将跳转到/posts/5?arg_one=one&amp;arg_two=two 也可以将多值参数传递给url_for1url = app.url_for('post_handler', post_id=5, arg_one=['one', 'two']) 上面代码在请求访问/时，将跳转到/posts/5?arg_one=one&amp;arg_one=two 其他特殊参数 (_anchor, _external, _scheme, _method, _server) 1234567891011121314url = app.url_for('post_handler', post_id=5, arg_one='one', _anchor='anchor')# /posts/5?arg_one=one#anchorurl = app.url_for('post_handler', post_id=5, arg_one='one', _external=True)# //server/posts/5?arg_one=one# _external requires you to pass an argument _server or set SERVER_NAME in app.config if not url will be same as no _externalurl = app.url_for('post_handler', post_id=5, arg_one='one', _scheme='http', _external=True)# http://server/posts/5?arg_one=one# when specifying _scheme, _external must be True# you can pass all special arguments at onceurl = app.url_for('post_handler', post_id=5, arg_one=['one', 'two'], arg_two=2, _anchor='anchor', _scheme='http', _external=True, _server='another_server:8888')# http://another_server:8888/posts/5?arg_one=one&amp;arg_one=two&amp;arg_two=2#anchor websocket路由可以使用@app.websocket装饰器定义WebSocket协议的路由。使用请求作为第一个参数，调用websocket协议对象作为第二个参数来调用websocket路由的处理程序，send和recv方法分别用于发送和接受数据。 12345678@app.websocket('/feed')async def feed(request, ws): while True: data = 'hello!' print('Sending: ' + data) await ws.send(data) data = await ws.recv() print('Received: ' + data) 或者： 1234async def feed(request, ws): passapp.add_websocket_route(my_websocket_handler, '/feed') strict_slashes 禁止请求尾部带/1234@app.get('/get', strict_slashes=True)def handler(request): return text('OK') 解析url中参数url格式为：?key1=value1&amp;key2=value2args - url参数将被解析成{‘key1’：[‘value1’]，’key2’：[‘value2’]}}格式。query_args - url参数将被解析成[（’key1’，’value1’），（’key2’，’value2’）]格式。query_string - url参数解析为key1=value1&amp;key2=value2格式。 123456789101112131415161718from sanic import Sanicfrom sanic.response import jsonapp = Sanic(__name__)@app.route("/")async def test(request): return json(&#123; "parsed": True, "url": request.url, "query_string": request.query_string, "args": request.args, "query_args": request.query_args &#125;)if __name__ == '__main__': app.run(host="0.0.0.0",port=8000) OutPut: 12345678910111213141516171819202122232425&#123; 'parsed': True, 'url': 'http://127.0.0.1:8000/?a=1&amp;b=2', 'query_string': 'a=1&amp;b=2', 'args': &#123; 'a': [ '1' ], 'b': [ '2' ] &#125;, 'query_args': [ [ 'a', '1' ], [ 'b', '2' ] ]&#125;&#125; 响应方式使用sanic.response模块中的函数来创建响应 纯文本 123456from sanic import response@app.route('/text')def handle_request(request): return response.text('Hello world!') HTML 123456from sanic import response@app.route('/html')def handle_request(request): return response.html('&lt;p&gt;Hello world!&lt;/p&gt;') json 123456from sanic import response@app.route('/json')def handle_request(request): return response.json(&#123;'message': 'Hello world!'&#125;) 文件 123456from sanic import response@app.route('/file')async def handle_request(request): return await response.file('/srv/www/whatever.png') 流媒体 12345678from sanic import response@app.route("/streaming")async def index(request): async def streaming_fn(response): await response.write('foo') await response.write('bar') return response.stream(streaming_fn, content_type='text/plain') 文件流对于大型文件，请结合使用上述文件和流技术 12345from sanic import response@app.route('/big_file.png')async def handle_request(request): return await response.file_stream('/srv/www/whatever.png') redirect 123456from sanic import response@app.route('/redirect')def handle_request(request): return response.redirect('/json') 空返回 12345from sanic import response@app.route('/empty')async def handle_request(request): return response.empty() 修改header和status 12345678910from sanic import response@app.route('/json')def handle_request(request): return response.json( &#123;'message': 'Hello world!'&#125;, headers=&#123;'X-Served-By': 'sanic'&#125;, status=200 )]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python web框架Sanic之Blueprints]]></title>
    <url>%2F2020%2F05%2F27%2FPython%20web%E6%A1%86%E6%9E%B6Sanic%E4%B9%8BBlueprints%2F</url>
    <content type="text"><![CDATA[简介Blueprints(蓝图)可用于在应用程序内进行子路由的对象，blueprints定义了添加路由的类似方法，而不是将路由添加到应用程序实例，将程序模块化，然后以灵活且可插入的方式向应用程序注册。blueprints对于大型应用程序特别有用。一个blueprints可以独立完成某一个任务，包括模板文件、静态文件、路由等都是独立的，而一个应用可以通过注册多个blueprints来进行构建。 简单demo认识下拆分模块my_blueprint.py 12345678910file: my_blueprint.pyfrom sanic.response import jsonfrom sanic import Blueprintbp = Blueprint('my_blueprint')@bp.route('/')async def bp_root(request): return json(&#123;'my': 'blueprint'&#125;) 注册blueprints,将子模块通过blueprint方法注册 123456789file: main.pyfrom sanic import Sanicfrom my_blueprint import bpapp = Sanic(__name__)app.blueprint(bp)app.run(host='0.0.0.0', port=8000, debug=True) blueprints 分组和嵌套blueprint 也可以被注册成列表或元组的一部分，注册将递归遍历blueprint的子序列，并加以注册。 分别初始化这个blueprint的嵌套结构里的文件 123456789# file: api/content/authors.pyfrom sanic import Blueprintfrom sanic import responseauthors = Blueprint('content_authors', url_prefix='/authors')@authors.route('/')async def home(request): return response.text(request.path) 12345678910# file: api/content/static.pyfrom sanic import Blueprintfrom sanic import responsestatic = Blueprint('content_static', url_prefix='/static')@static.route('/')async def home(request): return response.text(request.path) 12345678# file: api/content/__init__.pyfrom sanic import Blueprintfrom .static import staticfrom .authors import authorscontent = Blueprint.group(static, authors, url_prefix='/content') 123456789# file: api/info.pyfrom sanic import Blueprintfrom sanic import responseinfo = Blueprint('info', url_prefix='/info')@info.route('/')async def home(request): return response.text(request.path) 1234567# file: api/__init__.pyfrom sanic import Blueprintfrom .content import contentfrom .info import infoapi = Blueprint.group(content, info, url_prefix='/api') 上面这组blueprint定义了一组api的路径，他们通过url_prefix这个参数，把路径的嵌套关系组织起来，把这组blueprint注册到应用程序 12345678910# file: app.pyfrom sanic import Sanicfrom api import apiapp = Sanic(__name__)app.blueprint(api)if __name__ == '__main__': app.run(host='127.0.0.1', port=8888, debug=True) 测试url： 123http://127.0.0.1:8888/api/info OutPut: /api/infohttp://127.0.0.1:8888/api/content/authors OutPut: /api/content/authorshttp://127.0.0.1:8888/api/content/static OutPut: /api/content/static Blueprints 中间件中间件是在服务器请求运行前或运行后执行的函数，被用来修改请求和响应。有request和response两种中间件，均通过@app.middleware装饰器来声明，装饰器的参数是字符串，类型有request和response。response中间件同时接收request和response参数。 Blueprints 其他使用开始和停止blueprints可以在服务器的启动和停止过程中运行功能。当以多处理器模式运行时，则在程序派生后触发这些操作。可用的事件： before_server_start：在服务器开始接受连接前执行。 after_server_start： 在服务器开始接受连接后执行。 before_server_stop： 在服务器停止接受连接前执行。 after_server_stop: 在服务器停止并且所有请求都完成后执行。 下面一个小例子，在开始之前与数据库建立连接，停止及请求结束后断开数据库连接 12345678910111213from sanic import Sanicfrom sanic import Blueprintbp = Blueprint(__name__)@bp.listener('before_server_start')async def setup_connection(app,loop): global database database = mysql.connect(host='127.0.0.1')@bp.listener('after_server_stop')async def close_connection(app,loop): await database.close() API版本控制Blueprints对API版本控制非常有用，/v1/api，/v2/api将路由指向对应的blueprints version参数可选，该参数将放在该蓝图上定义的所有路由之前。 123456789101112131415file: my_blueprint.pyfrom sanic import Blueprintfrom sanic.response import textbp_v1 = Blueprint('v1',url_prefix='/api',version='v1')bp_v2 = Blueprint('v2',url_prefix='/api',version='v2')@bp_v1.route('/')async def api_v1_root(request): return text('welcome to api v1')@bp_v2.route('/')async def api_v2_root(request): return text('welcome to api v2') 123456789# main.pyfrom sanic import Sanicfrom blueprints import blueprint_v1, blueprint_v2app = Sanic(__name__)app.blueprint(blueprint_v1)app.blueprint(blueprint_v2)app.run(host='0.0.0.0', port=8000, debug=True) 验证： 12http://10.134.2.29:8000/v1/api OutPut: welcome to api v1http://10.134.2.29:8000/v2/api OutPut: welcome to api v2 使用url_for构建URL123456789@bp_v1.route('/')async def root(request): url = request.app.url_for('v1.post_handler', post_id=5) return redirect(url)@bp_v1.route('/post/&lt;post_id&gt;')async def post_handler(request, post_id): return text('Post &#123;&#125; in Blueprint V1'.format(post_id)) 验证： 12http://10.134.2.29:8000/v1/api 跳转到http://10.134.2.29:8000/v1/api/post/5 OutPut：Post 5 in Blueprint V1http://10.134.2.29:8000/v2/api 跳转到http://10.134.2.29:8000/v2/api/post/5 OutPut：Post 5 in Blueprint V2]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python web框架Sanic之路由]]></title>
    <url>%2F2020%2F05%2F26%2FPython%20web%E6%A1%86%E6%9E%B6Sanic%E4%B9%8B%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"><![CDATA[路由sanic中可以用app.route装饰器来定义路由，Route允许用户为不同的URL指定处理程序。 1234567891011from sanic import Sanicfrom sanic.response import jsonapp = Sanic("hayder")@app.route("/")async def test(request): return json(&#123;"hello": "world"&#125;)if __name__ == "__main__": app.run(host="0.0.0.0", port=8000) 如上demo，当访问服务端:8000/时，将请求url与app.route装饰器定义的路由进行匹配，然后执行相应的处理函数并返回json对象。 请求参数Sanic 带有支持请求参数的基本路由请求参数将作为关键字参数传递给路由对应的程序处理。 1234567from sanic.response import textfrom sanic import Sanicapp = Sanic(__name__)@app.route('/tag/&lt;tag&gt;')async def tag_handler(request, tag): return text('Tag - &#123;&#125;'.format(tag)) 如果要指定参数类型，需要加上&lt;&gt;，并指定参数的type(:type)，如果参数与指定的类型不匹配，将抛出NotFound异常，404错误。支持的类型如下： 字符串string 整形int number path uuid 1234567891011121314151617181920212223242526272829303132333435from sanic.response import textfrom sanic import Sanicapp = Sanic(__name__)@app.route('/string/&lt;string_arg:string&gt;')async def string_handler(request, string_arg): return text('String - &#123;&#125;'.format(string_arg))@app.route('/int/&lt;integer_arg:int&gt;')async def integer_handler(request, integer_arg): return text('Integer - &#123;&#125;'.format(integer_arg))@app.route('/number/&lt;number_arg:number&gt;')async def number_handler(request, number_arg): return text('Number - &#123;&#125;'.format(number_arg))@app.route('/alpha/&lt;alpha_arg:alpha&gt;')async def number_handler(request, alpha_arg): return text('Alpha - &#123;&#125;'.format(alpha_arg))@app.route('/path/&lt;path_arg:path&gt;')async def number_handler(request, path_arg): return text('Path - &#123;&#125;'.format(path_arg))@app.route('/uuid/&lt;uuid_arg:uuid&gt;')async def number_handler(request, uuid_arg): return text('Uuid - &#123;&#125;'.format(uuid_arg))@app.route('/person/&lt;name:[A-z]+&gt;')async def person_handler(request, name): return text('Person - &#123;&#125;'.format(name))@app.route('/folder/&lt;folder_id:[A-z0-9]&#123;0,4&#125;&gt;')async def folder_handler(request, folder_id): return text('Folder - &#123;&#125;'.format(folder_id)) HTTP请求类型默认情况下，URL上定义的路由仅可用于该URL的GET请求，但是@app.route装饰器接受可选参数method。 123456789101112131415from sanic.response import textfrom sanic import Sanicapp = Sanic(__name__)@app.route('/post', methods=['POST'])#也可以写成下面这种方式#@app.post('/post')async def post_handler(request): return text('POST request - &#123;&#125;'.format(request.json))@app.route('/get', methods=['GET'])#也可以写成下面这种方式#@app.get('/get')async def get_handler(request): return text('GET request - &#123;&#125;'.format(request.args)) 对上面代码测试访问， 12345678910111213import requestsimport jsonurl = "http://127.0.0.1:8000/post"req1 = requests.post(url="http://127.0.0.1:8000/post",data=json.dumps(&#123;"a":"b"&#125;))req2 = requests.get(url="http://127.0.0.1:8000/get?a=1")print(req1.text)print(req2.text)OutPut：POST request - &#123;'a': 'b'&#125;GET request - &#123;'a': ['1']&#125; 还有一个可选的参数host，对路由进行限制 123456789#如果host header匹配到example.com，将会使用下面的限制路由@app.route('/get', methods=['GET'], host='example.com')async def get_handler(request): return text('GET request - &#123;&#125;'.format(request.args))# 如果host header没有匹配到 example.com, 将会使用下面的默认路由@app.route('/get', methods=['GET'])async def get_handler(request): return text('GET request in default - &#123;&#125;'.format(request.args)) add_route()方法@app.route方法实际上只是app.add_route()的语法糖。实际等于 123456789from sanic.response import textfrom sanic import Sanicapp = Sanic(__name__)async def person_handler2(request, name): return text('Person - &#123;&#125;'.format(name)) app.add_route(person_handler2, '/person/&lt;name:[A-z]&gt;', methods=['GET']) url_forSanic提供了url_for方法，用于根据处理程序方法名称生成URL，如果要避免将url路径硬编码到应用程序中，这将很有用。 123456789101112131415from sanic.response import redirectfrom sanic import Sanicapp = Sanic(__name__)@app.route('/')async def index(request): # generate a URL for the endpoint `post_handler` url = app.url_for('post_handler', post_id=5) # the URL is `/posts/5`, redirect to it return redirect(url)@app.route('/posts/&lt;post_id&gt;')async def post_handler(request, post_id): return text('Post - &#123;&#125;'.format(post_id)) 请求/时会跳转到/posts/5 传递给url_for的不是请求参数的关键字参数将包含在URL的查询字符串中。1url = app.url_for('post_handler', post_id=5, arg_one='one', arg_two='two') 上面代码在请求访问/时，将跳转到/posts/5?arg_one=one&amp;arg_two=two 也可以将多值参数传递给url_for1url = app.url_for('post_handler', post_id=5, arg_one=['one', 'two']) 上面代码在请求访问/时，将跳转到/posts/5?arg_one=one&amp;arg_one=two 其他特殊参数 (_anchor, _external, _scheme, _method, _server) 1234567891011121314url = app.url_for('post_handler', post_id=5, arg_one='one', _anchor='anchor')# /posts/5?arg_one=one#anchorurl = app.url_for('post_handler', post_id=5, arg_one='one', _external=True)# //server/posts/5?arg_one=one# _external requires you to pass an argument _server or set SERVER_NAME in app.config if not url will be same as no _externalurl = app.url_for('post_handler', post_id=5, arg_one='one', _scheme='http', _external=True)# http://server/posts/5?arg_one=one# when specifying _scheme, _external must be True# you can pass all special arguments at onceurl = app.url_for('post_handler', post_id=5, arg_one=['one', 'two'], arg_two=2, _anchor='anchor', _scheme='http', _external=True, _server='another_server:8888')# http://another_server:8888/posts/5?arg_one=one&amp;arg_one=two&amp;arg_two=2#anchor websocket路由可以使用@app.websocket装饰器定义WebSocket协议的路由。使用请求作为第一个参数，调用websocket协议对象作为第二个参数来调用websocket路由的处理程序，send和recv方法分别用于发送和接受数据。 12345678@app.websocket('/feed')async def feed(request, ws): while True: data = 'hello!' print('Sending: ' + data) await ws.send(data) data = await ws.recv() print('Received: ' + data) 或者： 1234async def feed(request, ws): passapp.add_websocket_route(my_websocket_handler, '/feed') strict_slashes 禁止请求尾部带/1234@app.get('/get', strict_slashes=True)def handler(request): return text('OK') 解析url中参数url格式为：?key1=value1&amp;key2=value2args - url参数将被解析成{‘key1’：[‘value1’]，’key2’：[‘value2’]}}格式。query_args - url参数将被解析成[（’key1’，’value1’），（’key2’，’value2’）]格式。query_string - url参数解析为key1=value1&amp;key2=value2格式。 123456789101112131415161718from sanic import Sanicfrom sanic.response import jsonapp = Sanic(__name__)@app.route("/")async def test(request): return json(&#123; "parsed": True, "url": request.url, "query_string": request.query_string, "args": request.args, "query_args": request.query_args &#125;)if __name__ == '__main__': app.run(host="0.0.0.0",port=8000) OutPut: 12345678910111213141516171819202122232425&#123; 'parsed': True, 'url': 'http://127.0.0.1:8000/?a=1&amp;b=2', 'query_string': 'a=1&amp;b=2', 'args': &#123; 'a': [ '1' ], 'b': [ '2' ] &#125;, 'query_args': [ [ 'a', '1' ], [ 'b', '2' ] ]&#125;&#125; 响应方式使用sanic.response模块中的函数来创建响应 纯文本 123456from sanic import response@app.route('/text')def handle_request(request): return response.text('Hello world!') HTML 123456from sanic import response@app.route('/html')def handle_request(request): return response.html('&lt;p&gt;Hello world!&lt;/p&gt;') json 123456from sanic import response@app.route('/json')def handle_request(request): return response.json(&#123;'message': 'Hello world!'&#125;) 文件 123456from sanic import response@app.route('/file')async def handle_request(request): return await response.file('/srv/www/whatever.png') 流媒体 12345678from sanic import response@app.route("/streaming")async def index(request): async def streaming_fn(response): await response.write('foo') await response.write('bar') return response.stream(streaming_fn, content_type='text/plain') 文件流对于大型文件，请结合使用上述文件和流技术 12345from sanic import response@app.route('/big_file.png')async def handle_request(request): return await response.file_stream('/srv/www/whatever.png') redirect 123456from sanic import response@app.route('/redirect')def handle_request(request): return response.redirect('/json') 空返回 12345from sanic import response@app.route('/empty')async def handle_request(request): return response.empty() 修改header和status 12345678910from sanic import response@app.route('/json')def handle_request(request): return response.json( &#123;'message': 'Hello world!'&#125;, headers=&#123;'X-Served-By': 'sanic'&#125;, status=200 )]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django ORM读写分离]]></title>
    <url>%2F2019%2F12%2F19%2Fdjango%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[准备 准备两台mysql数据库，并配置好主从具体操作略，这里我用的是docker起的两个数据库容器。ip分别为172.17.0.2,172.17.0.3。 django项目python==3.6.5django==2.2.3 123django-admin startproject multidbcd multidbpython manage.py startapp app 配置django 配置mysql 1234567891011121314151617181920settings.py:INSTALL_APP 添加 'app'。DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'multidb', 'USER':'root', 'PASSWORD':'123456', 'HOST': '172.17.0.2' &#125;, 'slave': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'multidb', 'USER':'root', 'PASSWORD':'123456', 'HOST': '172.17.0.3' &#125;&#125; 创建Products表 12345678app/models.pyfrom django.db import models# Create your models here.class Products(models.Model): prod_name = models.CharField(max_length=32) prod_price = models.DecimalField(max_digits=6,decimal_places=2) 执行数据库迁移操作 12python manage.py makemigrationspython manage.py migrate 设置读写分离读写分离有两种方法：手动读写分离和自动读写分离 手动读写分离在需要使用数据库时手动通过.using(db) 来指定需要使用的库 123456python manage.py shellIn [1]: from app.models import ProductsIn [2]: Products.objects.using('default').create(prod_name='hayder',prod_price='1.3') Out[2]: &lt;Products: Products object (3)&gt; 自动读写分离需要配置数据库路由来自动实现，这样就不用每次读写时指定响应的数据库。 新建数据库路由脚本 1234567891011121314151617181920212223settings.py同级目录新建route.pyclass DefaultRouter(object): def db_for_read(self, model, **hints): print('read from slave.') return 'slave' def db_for_write(self, model, **hints): print('write to defalut.') return 'default' def allow_relation(self, obj1, obj2, **hints): return None def allow_migrate(self, db, app_label, model=None, **hints): return Nonedb_for_read 进行读操作的路由策略。db_for_write 增删改操作在default配置的数据库（主库）进行allow_relation 确定obj1和obj2之间是否可以产生关联， 主要用于foreign key和 many to many操作。allow_migrate 确定migrate操作是否可以在别名为db的数据库上运行。 settings.py 里配置Router 1DATABASE_ROUTERS = ['multidb.router.DefaultRouter'] 验证可以看到写操作对应的输出为db_for_write函数，读操作对应的输出为db_for_read函数 123456789101112python manage.py shellIn [1]: from app.models import Products In [2]: Products.objects.create(prod_name='hayder2',prod_price='3.14') write to defalut.Out[2]: &lt;Products: Products object (6)&gt;In [3]: Products.objects.all() Out[3]: read from slave.&lt;QuerySet [&lt;Products: Products object (6)&gt;]&gt; 一主多从情况如果你的环境是一主多从情况，db_for_read需要配置随机选择一台从服务器进行读操作settings.py里再配置多个数据库（slave1，slave2…..） 123456def db_for_read(self, model, **hints): import random choiced = random.choice(['slave','slave1','slave2'....]) print('read from &#123;&#125;.'.format(choiced)) return choiced 分库情况如果需要不同的app使用不同的库，可以利用model中的app_label来实现db的路由 123456def db_for_read(self, model, **hints): if model._meta.app_label == 'app01': import random return random.choice(['app01_slave','app01_slave1','app01_slave2'....]) if model._meta.app_label == 'app02': return 'app02_slave']]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python，Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django-rest-framework Token认证]]></title>
    <url>%2F2019%2F11%2F28%2Fdjango-rest-framework%20Token%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[创建demo项目1234pip install djangorestframeworkdjango-admin startproject myapicd myapidjango-admin startapp core 添加app到settings.py 12345678910INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'core.apps.CoreConfig', 'rest_framework',] 执行迁移数据库 1python manage.py migrate 创建api视图123456789myapi/core/views.pyfrom rest_framework.views import APIViewfrom rest_framework.response import Responseclass HelloView(APIView): def get(self, request): content = &#123;'message': 'Hello, World!'&#125; return Response(content) 添加路由12345678myapi/urls.pyfrom django.urls import pathfrom myapi.core import viewsurlpatterns = [ path('hello/', views.HelloView.as_view(), name='hello'),] 这时，我们通过GET请求访问/hello/方法可以获取对应数据 12345678910111213[xu-pc myapi]# http http://10.133.3.35:8000/hello/HTTP/1.1 200 OKAllow: GET, HEAD, OPTIONSContent-Length: 25Content-Type: application/jsonDate: Thu, 28 Nov 2019 06:00:43 GMTServer: WSGIServer/0.2 CPython/3.6.5Vary: AcceptX-Frame-Options: SAMEORIGIN&#123; "message": "hello,world"&#125; 添加权限限制123456789101112myapi/core/views.pyfrom rest_framework.views import APIViewfrom rest_framework.response import Responsefrom rest_framework.permissions import IsAuthenticatedclass HelloView(APIView): permission_classes = (IsAuthenticated,) def get(self, request): content = &#123;'message': 'Hello, World!'&#125; return Response(content) 重新访问会返回403错误 12345678910111213[xu-pc myapi]# http http://10.133.3.35:8000/hello/HTTP/1.1 403 ForbiddenAllow: GET, HEAD, OPTIONSContent-Length: 58Content-Type: application/jsonDate: Thu, 28 Nov 2019 06:06:35 GMTServer: WSGIServer/0.2 CPython/3.6.5Vary: Accept, CookieX-Frame-Options: SAMEORIGIN&#123; "detail": "Authentication credentials were not provided."&#125; 添加authorizen 认证settings.py添加APP 1234567891011121314151617INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'core.apps.CoreConfig', 'rest_framework', 'rest_framework.authtoken']REST_FRAMEWORK = &#123; 'DEFAULT_AUTHENTICATION_CLASSES': [ 'rest_framework.authentication.TokenAuthentication', ],&#125; 重新执行迁移数据库以创建存储认证令牌的表 123456[xu-pc myapi]# python manage.py migrateOperations to perform: Apply all migrations: admin, auth, authtoken, contenttypes, sessionsRunning migrations: Applying authtoken.0001_initial... OK Applying authtoken.0002_auto_20160226_1747... OK 创建用户并生成令牌123[xu-pc myapi]# python manage.py createsuperuser --username admin[xu-pc myapi]# python manage.py drf_create_token adminGenerated token b2a929c428f711e3934e98c752c00c111f21bc2e for user admin 请求测试如果不加token访问会返回401错误。 1234567891011121314[xu-pc myapi]# http http://10.133.3.35:8000/hello/HTTP/1.1 401 UnauthorizedAllow: GET, HEAD, OPTIONSContent-Length: 58Content-Type: application/jsonDate: Thu, 28 Nov 2019 06:26:59 GMTServer: WSGIServer/0.2 CPython/3.6.5Vary: AcceptWWW-Authenticate: TokenX-Frame-Options: SAMEORIGIN&#123; "detail": "Authentication credentials were not provided."&#125; 将’Authorization: Token xxx’加入请求头进行请求。 12345678910111213[xu-pc myapi]# http http://127.0.0.1:8000/hello/ 'Authorization: Token b2a929c428f711e3934e98c752c00c111f21bc2e'HTTP/1.1 200 OKAllow: GET, HEAD, OPTIONSContent-Length: 25Content-Type: application/jsonDate: Thu, 28 Nov 2019 05:27:25 GMTServer: WSGIServer/0.2 CPython/3.6.5Vary: AcceptX-Frame-Options: SAMEORIGIN&#123; "message": "hello,world"&#125; 用户获取token实际工作中，token一般是由用户自己获取的，我们需要编写一个获取token的视图函数 1234567891011myapi/urls.pyfrom django.urls import pathfrom rest_framework.authtoken.views import obtain_auth_tokenfrom myapi.core import viewsurlpatterns = [ path('hello/', views.HelloView.as_view(), name='hello'), path('api-token-auth/', obtain_auth_token, name='api_token_auth'),] 访问/api-token-auth/方法获取token 123456789101112[xu-pc myapi]# http http://127.0.0.1:8000/api-token-auth/ username=admin password=xxxxxxxHTTP/1.1 200 OKAllow: POST, OPTIONSContent-Length: 52Content-Type: application/jsonDate: Thu, 28 Nov 2019 06:19:50 GMTServer: WSGIServer/0.2 CPython/3.6.5X-Frame-Options: SAMEORIGIN&#123; "token": "b2a929c428f711e3934e98c752c00c111f21bc2e"&#125; 设置token过期时间设置token过期时间需要自定义获取token方法，继承ObtainAuthToken并重写post方法。判断token获取时间，如果超过自定义过期时间删除token并重新获取，工程下新建apis目录，apis目录中新建auth.py，authentication.py文件说明： auth.py： 请求获取token时 authentication.py： 每次带token请求数据时 123456789101112131415161718192021222324252627282930313233343536myapi/apis/auth.py# coding=utf8import datetime,pytzfrom django.conf import settingsfrom rest_framework import statusfrom rest_framework.response import Responsefrom rest_framework.authtoken.models import Tokenfrom rest_framework.authtoken.views import ObtainAuthTokenEXPIRE_MINUTES = getattr(settings, 'REST_FRAMEWORK_TOKEN_EXPIRE_MINUTES', 1)print(EXPIRE_MINUTES)class ObtainExpiringAuthToken(ObtainAuthToken): """Create user token""" def post(self, request): serializer = self.serializer_class(data=request.data) if serializer.is_valid(): token, created = Token.objects.get_or_create(user=serializer.validated_data['user']) time_now = datetime.datetime.now().replace(tzinfo=pytz.timezone('UTC')) print(token.created,time_now) print("----------------", token.created,time_now - datetime.timedelta(minutes=EXPIRE_MINUTES)) if created or token.created &lt; time_now - datetime.timedelta(minutes=EXPIRE_MINUTES): # Update the created time of the token to keep it valid token.delete() token = Token.objects.create(user=serializer.validated_data['user']) token.created = time_now token.save() return Response(&#123;'token': token.key&#125;) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) 123456789101112131415161718192021222324252627282930313233343536373839404142434445myapi/apis/authentication.py## coding=utf8import datetime,pytzfrom django.conf import settingsfrom rest_framework.authentication import TokenAuthenticationfrom rest_framework import exceptionsfrom django.utils.translation import ugettext_lazy as _from django.core.cache import cacheEXPIRE_MINUTES = getattr(settings, 'REST_FRAMEWORK_TOKEN_EXPIRE_MINUTES', 1)class ExpiringTokenAuthentication(TokenAuthentication): """Set up token expired time""" def authenticate_credentials(self, key): # Search token in cache cache_user = cache.get(key) if cache_user: return (cache_user, key) model = self.get_model() try: token = model.objects.select_related('user').get(key=key) except model.DoesNotExist: raise exceptions.AuthenticationFailed(_('Invalid token.')) if not token.user.is_active: raise exceptions.AuthenticationFailed(_('User inactive or deleted.')) time_now = datetime.datetime.now().replace(tzinfo=pytz.timezone('UTC')) if token.created &lt; time_now - datetime.timedelta(minutes=EXPIRE_MINUTES): token.delete() raise exceptions.AuthenticationFailed(_('Token has expired then delete.')) if token: # Cache token cache.set(key, token.user, EXPIRE_MINUTES) return (token.user, token) settings.py中修改REST_FRAMEWORK,apis.authentication.ExpiringTokenAuthentication替换掉rest_framework.authentication.TokenAuthentication 12345678REST_FRAMEWORK = &#123; 'DEFAULT_AUTHENTICATION_CLASSES': [ #'rest_framework.authentication.TokenAuthentication', 'apis.authentication.ExpiringTokenAuthentication' ],&#125;REST_FRAMEWORK_TOKEN_EXPIRE_MINUTES = 1 #Token过期时间（分钟）]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python，Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ngx_http_proxy_module模块]]></title>
    <url>%2F2019%2F07%2F29%2FNginx%20Proxy%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[指令proxy_buffer_size 语法：proxy_buffer_size size 默认值：proxy_buffer_size 4k|8k； 上下文：http，server，location 设置缓冲区的大小为size，nginx从被代理的服务器读取响应时，使用该缓冲区保存响应的开始部分，这部分通常包含一个小小的响应头，该缓冲区大小默认为proxy_buffers指令设置的一块缓冲区的大小。 proxy_buffering 语法： proxy_buffering on |off 默认值： proxy_buffering on； 上下文： http，server，location 代理的时候，开启或关闭缓冲后端服务器的响应。 当开启缓冲时，nginx尽可能快地从被代理的服务器接收响应，再将它存入proxy_buffer_size和proxy_buffers指令设置的缓冲区中。如果响应无法整个纳入内存，那么其中一部分将存入磁盘上的临时文件proxy_max_temp_file_size和proxy_temp_file_write_size指令可以控制临时文件的写入。当关闭缓冲时，收到响应后，nginx立即将其同步传给客户端。nginx不会尝试从被代理的服务器读取整个请求，而是将proxy_buffer_size指令设定的大小作为一次读取的最大长度。 proxy_buffers 语法：proxy_buffers number size; 默认值：proxy_buffers 8 4k|8k; 上下文： http，server，location 为每个连接设置缓冲区的数量为number，每块缓冲区的大小为size。这些缓冲区用于保存从被代理的服务器读取的响应。每块缓冲区默认等于一个内存页的大小。这个值是4K还是8K，取决于平台。 proxu_busy_buffers_size 语法: proxy_busy_buffers_size size; 默认值: proxy_busy_buffers_size 8k|16k; 上下文: http, server, location 当开启缓冲响应的功能以后，在没有读到全部响应的情况下，写缓冲到达一定大小时，nginx一定会向客户端发送响应，直到缓冲小于此值。这条指令用来设置此值。 同时，剩余的缓冲区可以用于接收响应，如果需要，一部分内容将缓冲到临时文件。该大小默认是proxy_buffer_size和proxy_buffers指令设置单块缓冲大小的两倍。 proxy_cache 语法: proxy_cache zone | off; 默认值: proxy_cache off; 上下文: http, server, location 指定用于页面缓存的共享内存。同一块共享内存可以在多个地方使用。off参数可以屏蔽从上层配置继承的缓存功能。 proxy_cache_bypass 语法: proxy_cache_bypass string …; 默认值: — 上下文: http, server, location 定义nginx不从缓存取响应的条件。如果至少一个字符串条件非空而且非“0”，nginx就不会从缓存中去取响应： 12proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;proxy_cache_bypass $http_pragma $http_authorization; 本指令可和与proxy_no_cache一起使用。 proxy_cache_key语法: proxy_cache_key string;默认值: proxy_cache_key $scheme$proxy_host$request_uri;上下文: http, server, location定义如何生成缓存的键，比如 1proxy_cache_key "$host$request_uri $cookie_user"; 这条指令的默认值类似于下面字符串 1proxy_cache_key $scheme$proxy_host$uri$is_args$args; proxy_cache_valid 语法: proxy_cache_valid [code …] time; 默认值: — 上下文: http, server, location 为不同的响应状态码设置不同的缓存时间。比如，下面指令 12proxy_cache_valid 200 302 10m;proxy_cache_valid 404 1m; 设置状态码为200和302的响应的缓存时间为10分钟，状态码为404的响应的缓存时间为1分钟。 如果仅仅指定了time， 1proxy_cache_valid 5m; 那么只有状态码为200、300和302的响应会被缓存。 如果使用了any参数，那么就可以缓存任何响应： proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m;缓存参数也可以直接在响应头中设定。这种方式的优先级高于使用这条指令设置缓存时间。 “X-Accel-Expires”响应头可以以秒为单位设置响应的缓存时间，如果值为0，表示禁止缓存响应，如果值以@开始，表示自1970年1月1日以来的秒数，响应一直会被缓存到这个绝对时间点。 如果不含“X-Accel-Expires”响应头，缓存参数仍可能被“Expires”或者“Cache-Control”响应头设置。 如果响应头含有“Set-Cookie”，响应将不能被缓存。 这些头的处理过程可以使用指令proxy_ignore_headers忽略。 proxy_connect_timeout 语法: proxy_connect_timeout time; 默认值: proxy_connect_timeout 60s; 上下文: http, server, location 设置与后端服务器建立连接的超时时间。应该注意这个超时一般不可能大于75秒。 proxy_hide_header语法: proxy_hide_header field;默认值: —上下文: http, server, locationnginx默认不会将“Date”、“Server”、“X-Pad”，和“X-Accel-…”响应头发送给客户端。proxy_hide_header指令则可以设置额外的响应头，这些响应头也不会发送给客户端。相反的，如果希望允许传递某些响应头给客户端，可以使用proxy_pass_header指令。 proxy_http_version语法: proxy_http_version 1.0 | 1.1;默认值:proxy_http_version 1.0;上下文: http, server, location这个指令出现在版本 1.1.4. 设置代理使用的HTTP协议版本。默认使用的版本是1.0，而1.1版本则推荐在使用keepalive连接和 NTLM身份验证时一起使用。 proxy_ignore_client_abort 语法: proxy_ignore_client_abort on | off; 默认值: proxy_ignore_client_abort off; 上下文: http, server, location 决定当客户端在响应传输完成前就关闭连接时，nginx是否应关闭后端连接。 proxy_ignore_headers 语法: proxy_ignore_headers field …; 默认值: — 上下文: http, server, location 不处理后端服务器返回的指定响应头。下面的响应头可以被设置： “X-Accel-Redirect”，“X-Accel-Expires”，“X-Accel-Limit-Rate” (1.1.6)，“X-Accel-Buffering” (1.1.6)， “X-Accel-Charset” (1.1.6)，“Expires”，“Cache-Control”，和“Set-Cookie” (0.8.44)。 如果不被取消，这些头部的处理可能产生下面结果： “X-Accel-Expires”，“Expires”，“Cache-Control”，和“Set-Cookie” 设置响应缓存的参数； “X-Accel-Redirect”执行到指定URI的内部跳转； “X-Accel-Limit-Rate”设置响应到客户端的传输速率限制； “X-Accel-Buffering”启动或者关闭响应缓冲； “X-Accel-Charset”设置响应所需的字符集。proxy_intercept_errors 语法: proxy_intercept_errors on | off; 默认值: proxy_intercept_errors off; 上下文: http, server, location 当后端服务器的响应状态码大于等于400时，决定是否直接将响应发送给客户端，亦或将响应转发给nginx由error_page指令来处理。 proxy_max_temp_file_size 语法: proxy_max_temp_file_size size; 默认值: proxy_max_temp_file_size 1024m; 上下文: http, server, location 打开响应缓冲以后，如果整个响应不能存放在proxy_buffer_size和proxy_buffers指令设置的缓冲区内，部分响应可以存放在临时文件中。 这条指令可以设置临时文件的最大容量。而每次写入临时文件的数据量则由proxy_temp_file_write_size指令定义。将此值设置为0将禁止响应写入临时文件。 proxy_next_upstream 语法: proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_404 | off …; 默认值: proxy_next_upstream error timeout; 上下文: http, server, location 指定在何种情况下一个失败的请求应该被发送到下一台后端服务器： error: 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误； timeout: 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时； invalid_header: 后端服务器返回空响应或者非法响应头； http_500: 后端服务器返回的响应状态码为500； http_502: 后端服务器返回的响应状态码为502； http_503: 后端服务器返回的响应状态码为503； http_504: 后端服务器返回的响应状态码为504； http_404: 后端服务器返回的响应状态码为404； off: 停止将请求发送给下一台后端服务器。 需要理解一点的是，只有在没有向客户端发送任何数据以前，将请求转给下一台后端服务器才是可行的。也就是说，如果在传输响应到客户端时出现错误或者超时，这类错误是不可能恢复的。proxy_pass 语法: proxy_pass URL; 默认值: — 上下文: location, if in location, limit_except 设置后端服务器的协议和地址，还可以设置可选的URI以定义本地路径和后端服务器的映射关系。 这条指令可以设置的协议是“http”或者“https”，而地址既可以使用域名或者IP地址加端口（可选）的形式来定义： 1proxy_pass http://localhost:8000/uri/; 又可以使用UNIX域套接字路径来定义。该路径接在“unix”字符串后面，两端由冒号所包围，比如： 1proxy_pass http://unix:/tmp/backend.socket:/uri/; 如果解析一个域名得到多个地址，所有的地址都会以轮转的方式被使用。当然，也可以使用服务器组来定义地址。 请求URI按下面规则传送给后端服务器： 如果proxy_pass使用了URI，当传送请求到后端服务器时，规范化以后的请求路径与配置中的路径的匹配部分将被替换为指令中定义的URI： 123location /name/ &#123; proxy_pass http://127.0.0.1/remote/;&#125; 如果proxy_pass没有使用URI，传送到后端服务器的请求URI一般客户端发起的原始URI，如果nginx改变了请求URI，则传送的URI是nginx改变以后完整的规范化URI： 123location /some/path/ &#123; proxy_pass http://127.0.0.1;&#125; 在1.1.12版以前，如果proxy_pass没有使用URI，某些情况下，nginx改变URI以后，会错误地将原始URI而不是改变以后的URI发送到后端服务器。某些情况下，无法确定请求URI中应该被替换的部分： 使用正则表达式定义路径。这种情况下，指令不应该使用URI。 在需要代理的路径中，使用rewrite指令改变了URI，但仍使用相同配置处理请求(break)： 1234location /name/ &#123; rewrite /name/([^/]+) /users?name=$1 break; proxy_pass http://127.0.0.1;&#125; 这种情况下，本指令设置的URI会被忽略，改变后的URI将被发送给后端服务器。 后端服务器的地址，端口和URI中都可以使用变量： 1proxy_pass http://$host$uri; 甚至像这样： 1proxy_pass $request; 这种情况下，后端服务器的地址将会在定义的服务器组中查找。如果查找不到，nginx使用resolver来查找该地址。 proxy_pass_header 语法: proxy_pass_header field; 默认值: — 上下文: http, server, location 允许传送被屏蔽的后端服务器响应头到客户端。 proxy_read_timeout 语法: proxy_read_timeout time; 默认值: proxy_read_timeout 60s; 上下文: http, server, location 定义从后端服务器读取响应的超时。此超时是指相邻两次读操作之间的最长时间间隔，而不是整个响应传输完成的最长时间。如果后端服务器在超时时间段内没有传输任何数据，连接将被关闭。 proxy_redirect 语法: proxy_redirect default; proxy_redirect off; proxy_redirect redirect replacement; 默认值: proxy_redirect default; 上下文: http, server, location proxy_send_timeout 语法: proxy_send_timeout time; 默认值: proxy_send_timeout 60s; 上下文: http, server, location 定义向后端服务器传输请求的超时。此超时是指相邻两次写操作之间的最长时间间隔，而不是整个请求传输完成的最长时间。如果后端服务器在超时时间段内没有接收到任何数据，连接将被关闭。 proxy_set_header 语法: proxy_set_header field value; 默认值: proxy_set_header Host $proxy_host; proxy_set_header Connection close; 上下文: http, server, location 允许重新定义或者添加发往后端服务器的请求头。value可以包含文本、变量或者它们的组合。 当且仅当当前配置级别中没有定义proxy_set_header指令时，会从上面的级别继承配置。 默认情况下，只有两个请求头会被重新定义： 12proxy_set_header Host $proxy_host;proxy_set_header Connection close; 如果不想改变请求头“Host”的值，可以这样来设置： 1proxy_set_header Host $http_host; 但是，如果客户端请求头中没有携带这个头部，那么传递到后端服务器的请求也不含这个头部。 这种情况下，更好的方式是使用$host变量——它的值在请求包含“Host”请求头时为“Host”字段的值，在请求未携带“Host”请求头时为虚拟主机的主域名： 1proxy_set_header Host $host; 此外，服务器名可以和后端服务器的端口一起传送： 1proxy_set_header Host $host:$proxy_port; 如果某个请求头的值为空，那么这个请求头将不会传送给后端服务器： 1proxy_set_header Accept-Encoding ""; 内嵌变量ngx_http_proxy_module支持内嵌变量，可以用于在proxy_set_header指令中构造请求头： 12$proxy_host后端服务器的主机名和端口； 12$proxy_port后端服务器的端口； 12$proxy_add_x_forwarded_for将$remote_addr变量值添加在客户端“X-Forwarded-For”请求头的后面，并以逗号分隔。 如果客户端请求未携带“X-Forwarded-For”请求头，$proxy_add_x_forwarded_for变量值将与$remote_addr变量相同。]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SaltStack]]></title>
    <url>%2F2019%2F07%2F29%2FSaltstack%2F</url>
    <content type="text"><![CDATA[Saltstack介绍特点 基于Python的C/S架构配置管理工具。 底层使用ZeroMQ消息队列pub/sub方式通信。 使用SSL证书签发的方式进行认证管理，传输采用AES加密。 服务架构在saltstack架构中服务端叫Master，客户端叫Minion。在Master和Minion段都是以守护进程的模式运行，一直监听配置文件里定义的ret_port(接受minion请求)和publish_port(发布消息)的端口。当Minion运行时会自动链接到配置文件里定义的Master地址ret_port端口进行连接认证。 运行方式- local： 本地运行 - Master/Minion：传统方式 - Syndic： 分布式 - Salt ssh组件介绍 组件 功能 Salt Master 用于将命令和配置发送到在受管系统上运行的Salt minion Salt Minion 从Salt master接收命令和配置 Execution Modules 实时监控，状态和库存；一次性命令和脚本；部署关键更新 Formulas (States) 系统配置的声明性或命令式表示 Grains Grains是有关底层受管系统的静态信息，包括操作系统，内存和许多其他系统属性。 Runners 在Salt master上执行的模块，用于执行支持任务。Salt runners报告作业状态，连接状态，从外部API读取数据，查询连接的Salt minions等。 Returners 将Salt minions返回的数据发送到另一个系统，例如数据库。Salt Returners可以在Salt minion或Salt master上运行。 Reactor 在SaltStack环境中发生事件时触发反应。 Salt SSH 在没有Salt minion的系统上通过SSH运行Salt命令。 SaltStack安装 ip 组件 192.168.111.43 salt salt-cloud salt-master salt-minion salt-ssh salt-syndic 192.168.111.45 salt-minion 配置yum源123rpm -ivh https://repo.saltstack.com/yum/redhat/salt-repo-latest-2.el7.noarch.rpm[root@Master ~]# yum -y install salt salt-cloud salt-master salt-minion salt-ssh salt-syndic[root@Minion ~]# yum -y install salt-minion 修改主控端配置文件，修改master地址和id1234[root@Master ~]# sed -i '/^#master:/a master: 192.168.111.43' /etc/salt/minion[root@Master ~]# sed -i '/^#id:/a id: 192.168.111.43' /etc/salt/minion[root@Minion ~]# sed -i '/^#master:/a master: 192.168.111.43' /etc/salt/minion[root@Minion ~]# sed -i '/^#id:/a id: 192.168.111.45' /etc/salt/minion 启动salt-master和salt-minion12[root@Master ~]# systemctl start salt-master &amp;&amp; systemctl start salt-minion &amp;&amp; systemctl enable salt-master &amp;&amp; systemctl enable salt-minion[root@Minion ~]# systemctl start salt-minion &amp;&amp; systemctl enable salt-minion 认证机制saltstack主控端是依靠openssl证书来与受控端主机认证通讯的，受控端启动后会发送给主控端一个公钥证书文件，在主控端用salt-key命令来管理证书。salt-minion与salt-master的认证过程： minion在第一次启动时，会在/etc/salt/pki/minion/下自动生成一对密钥，然后将公钥发给master master收到minion的公钥后，通过salt-key命令接受该公钥。此时master的/etc/salt/pki/master/minions目录将会存放以minion id命名的公钥，然后master就能对minion发送控制指令了 salt-key常用命令选项： -L 列出所有公钥信息 -a minion 接受指定minion等待认证的key -A 接受所有minion等待认证的key -r minion 拒绝指定minion等待认证的key -R 拒绝所有minion等待认证的key -f minion 显示指定key的指纹信息 -F 显示所有key的指纹信息 -d minion 删除指定minion的key -D 删除所有minion的key -y 自动回答yes查看并接受所有等待认证的key信息： 1234567[root@Master log]# salt-key -LAccepted Keys:Denied Keys:Unaccepted Keys:192.168.111.43192.168.111.45Rejected Keys: 123456789[root@Master log]# salt-key -yAThe following keys are going to be accepted:Unaccepted Keys:192.168.111.43192.168.111.45Key for minion 192.168.111.43 accepted.Key for minion 192.168.111.45 accepted.Key for minion Master accepted.Key for minion Minion accepted. 1234567[root@Master log]# salt-key -L Accepted Keys:192.168.111.43192.168.111.45Denied Keys:Unaccepted Keys:Rejected Keys: salt命令使用语法： salt [options] ‘‘ [arguments] 常用options --verion //查看saltstack版本号 --version-report //查看saltstack以及依赖包的版本号 -c CONFIG_DIR //指定配置文件目录(默认为/etc/salt) -t TIMEOUT //指定超时时间（默认5s） --async //异步执行 -v //verbose模式，详细显示执行过程 --username=USERNAME //指定外部认证用户名 --password=PASSWORD //指定外部认证密码 --log-file=LOG_FILE //指定日志记录文件常用target参数 -E //正则匹配 -L //列表匹配 -S //CIDR匹配网段 -G //grains匹配 --grain-pcre //grains加正则匹配 -N //组匹配 -R //范围匹配 -C //综合匹配（指定多个匹配） -I //pillar值匹配示例 12345[root@Master log]# salt -E "192*" test.ping192.168.111.43: True192.168.111.45: True 12345[root@Master log]# salt -L 192.168.111.43,192.168.111.45 test.ping192.168.111.43: True192.168.111.45: True 12345[root@Master log]# salt -S "192.168.111.0/24" test.ping192.168.111.45: True192.168.111.43: True 12345[root@Master log]# salt -G "os:centos" test.ping192.168.111.45: True192.168.111.43: True 123[root@Master log]# salt -N centos test.pingNode group centos unavailable in /etc/salt/master此处的centos是一个组名，需要在master配置文件中定义nodegroup参数，并需要知道monion的id信息才能将其定义至某个组里。 12345[root@Master log]# salt -C "G@os:centos or L@192.168.111.45" test.ping192.168.111.43: True192.168.111.45: True SaltStack配置管理SaltStack工程结构saltstack工程配置文件是由yaml格式编写，存放位置是由master配置文件中定义 12345[root@Master ~]# vim /etc/salt/masterfile_roots: base: - /srv/salt/base 配置一个apache实例在master上部署sls配置文件并执行12345678910111213[root@Master ~]# mkdir -p /srv/salt/&#123;base,test,dev,prod&#125;[root@Master ~]# cd /srv/salt/base/[root@Master ~]# vim apache.slsapache-install: pkg.installed: - names: - httpd - httpd-develapache-service: service.running: - name: httpd - enable: True 1[root@Master ~]# systemctl restart salt-master 执行状态描述文件: 1[root@Master ~]# salt '192.168.111.45' state.sls apache saltenv=base top filetop file介绍直接通过命令执行sls文件时够自动化吗？答案是否定的，因为我们还要告诉某台主机要执行某个任务，自动化应该是我们让它干活时，它自己就知道哪台主机要干什么活，但是直接通过命令执行sls文件并不能达到这个目的，为了解决这个问题，top file 应运而生。top file就是一个入口，top file的文件名可通过在 Master的配置文件中搜索top.sls找出，且此文件必须在 base 环境中，默认情况下此文件必须叫top.sls。top file的作用就是告诉对应的主机要干什么活，比如让web服务器启动web服务，让数据库服务器安装mysql等等。 12345678910[root@Master srv]# tree /srv/salt//srv/salt/├── base│ ├── apache.sls│ └── top.sls├── dev├── prod└── test4 directories, 2 files 1234cat /srv/salt/base/top.slsbase: '192.168.111.45': - apache 使用高级状态来执行：注意：top file里面的’‘ 表示的是所有要执行状态的目标，而salt ‘‘ state.highstate的’*’表示通知所有机器干活，而是否要干活则是由top file来指定的。加上test=true参数执行则不会真正的执行操作。 1[root@Master srv]# salt '*' state.highstate SaltStack数据系统SaltStack有两大数据系统： Grains Pillar SaltStack组件之GrainsGrains是saltstack一个非常重要的组件之一，存放着minion启动时收集到的信息，记录minion的一些静态信息，可以简单理解为记录每台minion的一些常用属性，比如主机名，CPU，内存，磁盘，网络信息等。可以通过grains.items查看某台minion的所有Grains信息。 信息实例查询列出所有grains的key和value 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299[root@Master log]# salt "192.168.111.45" grains.items192.168.111.45: ---------- SSDs: biosreleasedate: 04/05/2016 biosversion: 6.00 cpu_flags: - fpu - vme - de - pse - tsc - msr - pae - mce - cx8 - apic - sep - mtrr - pge - mca - cmov - pat - pse36 - clflush - dts - mmx - fxsr - sse - sse2 - ss - syscall - nx - pdpe1gb - rdtscp - lm - constant_tsc - arch_perfmon - pebs - bts - nopl - xtopology - tsc_reliable - nonstop_tsc - eagerfpu - pni - pclmulqdq - ssse3 - fma - cx16 - pcid - sse4_1 - sse4_2 - x2apic - movbe - popcnt - tsc_deadline_timer - aes - xsave - avx - f16c - rdrand - hypervisor - lahf_lm - abm - 3dnowprefetch - fsgsbase - tsc_adjust - bmi1 - hle - avx2 - smep - bmi2 - invpcid - rtm - rdseed - adx - smap - xsaveopt - ibpb - ibrs - stibp - arat - spec_ctrl - intel_stibp - arch_capabilities cpu_model: Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz cpuarch: x86_64 disks: - sda - sr0 - dm-0 - dm-1 dns: ---------- domain: ip4_nameservers: - 192.168.99.66 - 202.101.172.35 - 202.101.172.46 ip6_nameservers: nameservers: - 192.168.99.66 - 202.101.172.35 - 202.101.172.46 options: search: sortlist: domain: fqdn: Minion fqdn_ip4: - 192.168.111.45 fqdn_ip6: - fe80::a140:9424:7f60:f266 fqdns: gid: 0 gpus: |_ ---------- model: SVGA II Adapter vendor: vmware groupname: root host: Minion hwaddr_interfaces: ---------- ens192: 00:0c:29:e2:fd:39 lo: 00:00:00:00:00:00 id: 192.168.111.45 init: systemd ip4_gw: 192.168.111.254 ip4_interfaces: ---------- ens192: - 192.168.111.45 lo: - 127.0.0.1 ip6_gw: False ip6_interfaces: ---------- ens192: - fe80::a140:9424:7f60:f266 lo: - ::1 ip_gw: True ip_interfaces: ---------- ens192: - 192.168.111.45 - fe80::a140:9424:7f60:f266 lo: - 127.0.0.1 - ::1 ipv4: - 127.0.0.1 - 192.168.111.45 ipv6: - ::1 - fe80::a140:9424:7f60:f266 kernel: Linux kernelrelease: 3.10.0-862.el7.x86_64 kernelversion: #1 SMP Fri Apr 20 16:44:24 UTC 2018 locale_info: ---------- defaultencoding: UTF-8 defaultlanguage: en_US detectedencoding: UTF-8 localhost: Minion lsb_distrib_codename: CentOS Linux 7 (Core) lsb_distrib_id: CentOS Linux machine_id: 10fb57545175412dbbdead43d1270cd7 manufacturer: VMware, Inc. master: 192.168.111.43 mdadm: mem_total: 992 nodename: Minion num_cpus: 1 num_gpus: 1 os: CentOS os_family: RedHat osarch: x86_64 oscodename: CentOS Linux 7 (Core) osfinger: CentOS Linux-7 osfullname: CentOS Linux osmajorrelease: 7 osrelease: 7.5.1804 osrelease_info: - 7 - 5 - 1804 path: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin pid: 2558 productname: VMware Virtual Platform ps: ps -efHww pythonexecutable: /usr/bin/python pythonpath: - /usr/bin - /usr/lib64/python27.zip - /usr/lib64/python2.7 - /usr/lib64/python2.7/plat-linux2 - /usr/lib64/python2.7/lib-tk - /usr/lib64/python2.7/lib-old - /usr/lib64/python2.7/lib-dynload - /usr/lib64/python2.7/site-packages - /usr/lib/python2.7/site-packages pythonversion: - 2 - 7 - 5 - final - 0 saltpath: /usr/lib/python2.7/site-packages/salt saltversion: 2019.2.0 saltversioninfo: - 2019 - 2 - 0 - 0 selinux: ---------- enabled: True enforced: Permissive serialnumber: VMware-56 4d 71 53 1d bc 6a 67-13 b4 e3 88 5f e2 fd 39 server_id: 1370726209 shell: /bin/sh swap_total: 1639 systemd: ---------- features: +PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN version: 219 uid: 0 username: root uuid: 53714d56-bc1d-676a-13b4-e3885fe2fd39 virtual: VMware zfs_feature_flags: False zfs_support: False zmqversion: 4.1.4 只查询所有的grains的key 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[root@Master log]# salt "192.168.111.45" grains.ls192.168.111.45: - SSDs - biosreleasedate - biosversion - cpu_flags - cpu_model - cpuarch - disks - dns - domain - fqdn - fqdn_ip4 - fqdn_ip6 - fqdns - gid - gpus - groupname - host - hwaddr_interfaces - id - init - ip4_gw - ip4_interfaces - ip6_gw - ip6_interfaces - ip_gw - ip_interfaces - ipv4 - ipv6 - kernel - kernelrelease - kernelversion - locale_info - localhost - lsb_distrib_codename - lsb_distrib_id - machine_id - manufacturer - master - mdadm - mem_total - nodename - num_cpus - num_gpus - os - os_family - osarch - oscodename - osfinger - osfullname - osmajorrelease - osrelease - osrelease_info - path - pid - productname - ps - pythonexecutable - pythonpath - pythonversion - saltpath - saltversion - saltversioninfo - selinux - serialnumber - server_id - shell - swap_total - systemd - uid - username - uuid - virtual - zfs_feature_flags - zfs_support - zmqversion 查询某个key的值 123[root@Master log]# salt "192.168.111.45" grains.get fqdn_ip4192.168.111.45: - 192.168.111.45 1234567[root@Master log]# salt "192.168.111.45" grains.get ip4_interfaces192.168.111.45: ---------- ens192: - 192.168.111.45 lo: - 127.0.0.1 123[root@Master log]# salt "192.168.111.45" grains.get ip4_interfaces:ens192192.168.111.45: - 192.168.111.45 目标匹配实例用Grains来匹配minion： 123456在所有centos系统执行命令：[root@Master srv]# salt -G 'os:centos' cmd.run 'uptime'192.168.111.43: 03:38:03 up 4:30, 2 users, load average: 0.01, 0.06, 0.12192.168.111.45: 03:38:03 up 4:30, 2 users, load average: 0.00, 0.01, 0.05 自定义grains item 方式一：修改minion配置文件 1234567891011[root@Master ~]# vim /etc/salt/miniongrains: roles: - webserver - memcache[root@Master ~]# systemctl restart salt-minion[root@Master ~]# salt '*' grains.get roles192.168.111.45:192.168.111.43: - webserver - memcache 方式二: 自定义grains文件（生产环境推荐使用） 12345678910[root@Master ~]# vim /etc/salt/grainscloud: - openstack - kubernetes[root@Master ~]# systemctl restart salt-minion[root@Master ~]# salt '*' grains.get cloud192.168.111.45:192.168.111.43: - openstack - kubernetes 不重启minion使自定义生效： 1234567891011121314[root@Master salt]# salt '*' grains.get cloud192.168.111.43: - openstack - kubernetes192.168.111.45:[root@Master salt]# salt '*' saltutil.sync_grains192.168.111.43:192.168.111.45:[root@Master salt]# salt '*' grains.get cloud 192.168.111.43: - openstack - kubernetes - zabbix192.168.111.45: SaltStack组件之PillarPillar使SaltStack数据管理中心，经常配置states在大规模的配置管理工作中使用它。Pillar在SaltStack中主要的作用就是存储和定义配置管理中需要的一些数据，比如软件版本号，用户名密码等信息，它的定义存储格式和Grains类似，都是YAML格式。 Pillar的特点 可以给指定的minion定义它需要的数据 只有指定的人才能看到定义的数据 在master配置文件里设置 master配置文件定义默认Base环境下Pillar的工作目录是/srv/pillar目录下。默认salt ‘*’ pillar.items是没有任何信息的，需要在master配置文件中将pillar_opts: False 改为True。 Pillar自定义数据 打开master配置文件中的pillar_roots配置 1234567891011121314151617pillar_roots: base: - /srv/pillar/base prod: - /srv/pillar/prod[root@Master ~]# systemctl restart salt-master[root@Master ~]# mkdir -p /srv/pillar/&#123;base,prod&#125;[root@Master ~]# tree /srv/pillar//srv/pillar/├── base└── prod[root@Master ~]# vim /srv/pillar/base/apache.sls&#123;% if grains['os'] == 'CentOS' %&#125;apache: httpd&#123;% elif grains['os'] == 'Debian' %&#125;apache: apache2&#123;% endif %&#125; 定义top file入口文件 1234567[root@master ~]# vim /srv/pillar/base/top.slsbase: '192.168.111.43': - apache 这个top.sls文件的意思表示的是192.168.111.43这台主机的base环境能够访问到apache这个pillar[root@master ~]# salt '*' pillar.items 在salt下修改apache的状态文件，引用pillar的数据 123456789[root@master ~]# vim /srv/salt/base/web/apache/apache.slsapache-install: pkg.installed: - name: &#123;&#123; pillar['apache'] &#125;&#125;apache-service: service.running: - name: &#123;&#123; pillar['apache'] &#125;&#125; - enable: True 执行高级状态文件 1[root@master ~]# salt '192.168.111.43' state.highstate SaltStack常用模块介绍SaltStack常用模块之networknetwork.active_tcp返回所有活动的tcp连接 1234567891011121314151617181920212223[root@Master ~]# salt '*' network.active_tcp192.168.111.45: ---------- 0: ---------- local_addr: 192.168.111.45 local_port: 22 remote_addr: 192.168.110.110 remote_port: 60119 1: ---------- local_addr: 192.168.111.45 local_port: 40558 remote_addr: 192.168.111.43 remote_port: 4505 network.calc_net通过ip和子网掩码计算出网段 12345678910[root@Master ~]# salt '*' network.calc_net 192.168.111.45 255.255.255.0192.168.111.45: 192.168.111.0/24192.168.111.43: 192.168.111.0/24[root@Master ~]# salt '*' network.calc_net 192.168.111.45 255.255.255.240192.168.111.43: 192.168.111.32/28192.168.111.45: 192.168.111.32/28 network.connect测试minion至某一台服务器的网络是否连通 12345678910111213[root@Master ~]# salt '*' network.connect badu.com 80192.168.111.43: ---------- comment: Successfully connected to badu.com (47.254.33.193) on tcp port 80 result: True192.168.111.45: ---------- comment: Successfully connected to badu.com (47.254.33.193) on tcp port 80 result: True network.default_route查看默认路由 network.get_fqdn查看主机的fqdn(完全限定域名) 12345[root@Master ~]# salt '*' network.get_fqdn192.168.111.43: Master192.168.111.45: Minion network.get_hostname获取主机名 12345[root@Master ~]# salt '*' network.get_hostname192.168.111.43: Master192.168.111.45: Minion network.get_route查询到一个目标网络的路由信息 1234567891011[root@Master ~]# salt '192.168.111.45' network.get_route 192.168.111.254192.168.111.45: ---------- destination: 192.168.111.254 gateway: None interface: ens192 source: 192.168.111.45 network.hw_addr返回指定网卡的mac地址 123[root@Master ~]# salt '192.168.111.45' network.hw_addr ens192192.168.111.45: 00:0c:29:e2:fd:39 network.ifacestartswith从特定CIDR检索接口名称 123456[root@Master ~]# salt '192.168.111.45' network.ifacestartswith 192.168192.168.111.45: - ens192[root@Master ~]# salt '192.168.111.45' network.ifacestartswith 127.0192.168.111.45: - lo network.in_subnet判断当前主机是否在一个网段内 123[root@Master ~]# salt '192.168.111.45' network.in_subnet 192.168.111.0/24192.168.111.45: True network.interface返回指定网卡信息 123456789101112[root@Master ~]# salt '192.168.111.45' network.interface ens192192.168.111.45: |_ ---------- address: 192.168.111.45 broadcast: 192.168.111.255 label: ens192 netmask: 255.255.254.0 network.interface_ip返回指定网卡的ip地址 123[root@Master ~]# salt '192.168.111.45' network.interface_ip lo192.168.111.45: 127.0.0.1 network.ip_addrs返回一个ipv4的地址列表该函数会忽略127.0.0.1 123[root@Master ~]# salt '192.168.111.45' network.ip_addrs192.168.111.45: - 192.168.111.45 network.netstat返回所有打开的端口和状态 network.ping使用ping命令测试到某目标的连通性 123456789101112131415161718192021[root@Master ~]# salt '*' network.ping baidu.com192.168.111.45: PING baidu.com (39.156.69.79) 56(84) bytes of data. 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=1 ttl=50 time=33.7 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=2 ttl=50 time=34.2 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=3 ttl=50 time=33.6 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=4 ttl=50 time=34.3 ms --- baidu.com ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3004ms rtt min/avg/max/mdev = 33.654/33.991/34.355/0.385 ms192.168.111.43: PING baidu.com (39.156.69.79) 56(84) bytes of data. 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=1 ttl=50 time=33.6 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=2 ttl=50 time=33.9 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=3 ttl=50 time=34.4 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=4 ttl=50 time=33.6 ms --- baidu.com ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3004ms rtt min/avg/max/mdev = 33.628/33.915/34.411/0.306 ms network.reverse_ip返回一个指定的ip地址的反向地址 123[root@Master ~]# salt '192.168.111.45' network.reverse_ip 192.168.111.254 192.168.111.45: 254.111.168.192.in-addr.arpa SaltStack常用模块之serviceservice.available判断指定的服务是否在运行 12345[root@Master ~]# salt '*' service.available httpd 192.168.111.45: True192.168.111.43: False service.get_all获取所有正在运行的服务 123456789101112131415161718192021222324[root@Master ~]# salt '192.168.111.45' service.get_all 192.168.111.45: - NetworkManager - NetworkManager-dispatcher - NetworkManager-wait-online - arp-ethers - auditd - autovt@ - basic.target - blk-availability - bluetooth.target - brandbot - brandbot.path - chrony-dnssrv@ - chrony-dnssrv@.timer - chrony-wait - chronyd - console-getty - console-shell - container-getty@ - cpupower - crond ... ... service.disabled检查指定服务是否开机不自动启动 123[root@Master ~]# salt '192.168.111.45' service.disabled httpd192.168.111.45: False service.enabled检查指定服务是否是开机自启 123[root@Master ~]# salt '192.168.111.45' service.enabled httpd 192.168.111.45: True service.disable设置指定服务开机不自动启动 123456789[root@Master ~]# salt '192.168.111.45' service.enabled httpd 192.168.111.45: True[root@Master ~]# salt '192.168.111.45' service.disable httpd 192.168.111.45: True[root@Master ~]# salt '192.168.111.45' service.enabled httpd192.168.111.45: False service.enable设置指定服务开机自启动 123456789[root@Master ~]# salt '192.168.111.45' service.enabled httpd192.168.111.45: False[root@Master ~]# salt '192.168.111.45' service.enable httpd 192.168.111.45: True[root@Master ~]# salt '192.168.111.45' service.enabled httpd192.168.111.45: True service.reload重新加载指定服务 123[root@Master ~]# salt '192.168.111.45' service.reload httpd192.168.111.45: True service.stop停止指定服务 123[root@Master ~]# salt '192.168.111.45' service.stop httpd 192.168.111.45: True service.start启动指定服务 service.restart重启指定服务 service.status查看指定服务状态 SaltStack常用模块之pkgpkg.download只下载软件包但是不安装，会下载指定及其所有依赖包，需要在minion端安装yum-utils，可以使用cmd.run进行远程安装。 123456789[root@Master ~]# salt '*' pkg.download wget192.168.111.45: ---------- wget: /var/cache/yum/packages/wget-1.14-18.el7_6.1.x86_64.rpm192.168.111.43: ---------- wget: /var/cache/yum/packages/wget-1.14-18.el7_6.1.x86_64.rpm pkg.file_list列出指定包或系统中已安装的所有包的文件 pkg.group_info查看包组的信息 1234567891011121314151617181920212223[root@Master ~]# salt '*' pkg.group_info 'Development Tools'192.168.111.43: ---------- conditional: default: - byacc - cscope - ctags - diffstat - doxygen - elfutils - gcc-gfortran - git - indent - intltool - patchutils - rcs - subversion - swig - systemtap description: ... ... pkg.group_list列出系统中所有的包组 pkg.install安装软件 123456789101112131415[root@Master ~]# salt '*' pkg.install wget192.168.111.43: ---------- wget: ---------- new: 1.14-18.el7_6.1 old:192.168.111.45: ---------- wget: ---------- new: 1.14-18.el7_6.1 old: pkg.list_downloaded列出已下载到本地的软件包 123456789101112131415[root@Master ~]# salt '192.168.111.45' pkg.list_downloaded192.168.111.45: ---------- wget: ---------- 1.14-18.el7_6.1: ---------- creation_date_time: 2019-07-30T05:34:36 creation_date_time_t: 1564479276 path: /var/cache/yum/packages/wget-1.14-18.el7_6.1.x86_64.rpm size: 560272 pkg.list_pkgs以字典的方式列出当前已安装的软件包 1[root@Master ~]# salt '192.168.111.45' pkg.list_pkgs pkg.owner列出指定文件是由哪个包提供的 123[root@Master ~]# salt '192.168.111.45' pkg.owner /usr/sbin/sshd192.168.111.45: openssh-server pkg.remove卸载指定软件 12345678910111213[root@Master ~]# salt '192.168.111.45' pkg.remove httpd192.168.111.45: ---------- httpd: ---------- new: old: 2.4.6-89.el7.centos httpd-devel: ---------- new: old: 2.4.6-89.el7.centos pkg.upgrade升级系统中所有的软件包或者指定的软件包 123456789101112131415[root@Master ~]# salt '192.168.111.45' pkg.upgrade name=openssl192.168.111.45: ---------- openssl: ---------- new: 1:1.0.2k-16.el7_6.1 old: 1:1.0.2k-12.el7 openssl-libs: ---------- new: 1:1.0.2k-16.el7_6.1 old: 1:1.0.2k-12.el7 SaltStack常用模块之statestate.show_highstate显示当前系统中有哪些高级状态 12345678910111213141516171819202122232425262728293031323334353637383940[root@Master ~]# salt '192.168.111.45' state.show_highstate192.168.111.45: ---------- apache-install: ---------- __env__: base __sls__: apache pkg: |_ ---------- names: - httpd - httpd-devel - installed |_ ---------- order: 10000 apache-service: ---------- __env__: base __sls__: apache service: |_ ---------- name: httpd |_ ---------- enable: True - running |_ ---------- order: 10001 state.highstate执行高级状态 12345[root@Master base]# pwd/srv/salt/base[root@Master base]# lsapache.sls top.sls[root@Master base]# salt '192.168.111.45' state.highstate apache state.show_state_usage显示当前系统中的高级状态执行情况 1[root@Master base]# salt '192.168.111.45' state.show_state_usage state.show_top返回minion将用于highstate的顶级数据 1[root@Master base]# salt '192.168.111.45' state.show_top state.top执行指定的top file，而不是默认的 1[root@Master base]# salt '192.168.111.45' state.top top.sls state.show_sls显示master上特定sls或sls文件列表中的状态数据 1[root@Master base]# salt '192.168.111.45' state.show_sls apache SaltStack常用模块之salt-cpsalt-cp能很方便的把master上文件批量传到minion上 拷贝单个文件到目标主机1234567891011121314[root@Master base]# salt '192.168.111.45' cmd.run 'ls /usr/src/'192.168.111.45: debug kernels [root@Master base]# salt-cp '192.168.111.45' /etc/passwd /usr/src/192.168.111.45: ---------- /usr/src/passwd: True[root@Master base]# salt '192.168.111.45' cmd.run 'ls /usr/src/' 192.168.111.45: debug kernels passwd 拷贝多个文件到目标主机1234567891011121314[root@Master base]# salt-cp '192.168.111.45' /etc/shadow /etc/group /usr/src192.168.111.45: ---------- /usr/src/group: True /usr/src/shadow: True[root@Master base]# salt '192.168.111.45' cmd.run 'ls /usr/src'192.168.111.45: debug group kernels passwd shadow SaltStack常用模块之filefile.access检查指定路径是否存在123456[root@Master base]# salt '192.168.111.45' file.access '/hayder' f192.168.111.45: False[root@Master base]# salt '192.168.111.45' file.access '/etc' f 192.168.111.45: True 检查指定文件的权限信息12345678910111213[root@Master base]# salt '192.168.111.45' cmd.run 'ls -l /etc/passwd'192.168.111.45: -rw-r--r--. 1 root root 961 Jul 29 02:44 /etc/passwd[root@Master base]# salt '192.168.111.45' file.access /etc/passwd r192.168.111.45: True[root@Master base]# salt '192.168.111.45' file.access /etc/passwd w192.168.111.45: True[root@Master base]# salt '192.168.111.45' file.access /etc/passwd x192.168.111.45: False[root@Master base]# file.append往一个文件里追加内容，若此文件不存在则抛出异常 123456789101112[root@Master base]# salt '192.168.111.45' cmd.run 'cat /root/test'192.168.111.45: 123[root@Master base]# salt '192.168.111.45' file.append /root/test "hello world" "hayder" "lily"192.168.111.45: Wrote 3 lines to "/root/test"[root@Master base]# salt '192.168.111.45' cmd.run 'cat /root/test' 192.168.111.45: 123 hello world hayder lily file.basename获取指定路径的基名 123[root@Master base]# salt '192.168.111.45' file.basename '/etc/sysconfig/network'192.168.111.45: network file.dirname获取指定路径的目录名 123[root@Master base]# salt '192.168.111.45' file.dirname '/etc/sysconfig/network'192.168.111.45: /etc/sysconfig file.check_hash检查指定的文件与hash字符串是否匹配，匹配返回True，否则返回False 123456789[root@Master base]# salt '192.168.111.45' cmd.run 'md5sum /etc/passwd'192.168.111.45: 35392e59e565268c133a318187e1f8ac /etc/passwd[root@Master base]# salt '192.168.111.45' file.check_hash /etc/passwd 35392e59e565268c133a318187e1f8ac192.168.111.45: True[root@Master base]# salt '192.168.111.45' file.check_hash /etc/shadow 35392e59e565268c133a318187e1f8ac192.168.111.45: False file.chattr修改指定文件的属性 123456789101112131415[root@Master base]# salt '192.168.111.45' cmd.run 'lsattr /etc/passwd'192.168.111.45: ---------------- /etc/passwd[root@Master base]# salt '192.168.111.45' file.chattr /etc/passwd operator=add attributes=ai192.168.111.45: True[root@Master base]# salt '192.168.111.45' cmd.run 'lsattr /etc/passwd' 192.168.111.45: ----ia---------- /etc/passwd[root@Master base]# salt '192.168.111.45' file.chattr /etc/passwd operator=remove attributes=ai192.168.111.45: True[root@Master base]# salt '192.168.111.45' cmd.run 'lsattr /etc/passwd' 192.168.111.45: ---------------- /etc/passwd file.chown设置指定的文件的属主，属组信息 12345678910111213[root@Master base]# salt '192.168.111.45' cmd.run 'ls -l /root'192.168.111.45: total 8 -rw-------. 1 root root 1261 Jul 29 06:38 anaconda-ks.cfg -rw-r--r--. 1 root root 28 Jul 30 06:09 test[root@Master base]# salt '192.168.111.45' file.chown /root/test apache apache192.168.111.45: None[root@Master base]# salt '192.168.111.45' cmd.run 'ls -l /root' 192.168.111.45: total 8 -rw-------. 1 root root 1261 Jul 29 06:38 anaconda-ks.cfg -rw-r--r--. 1 apache apache 28 Jul 30 06:09 test file.copy在远程主机上复制文件或目录 拷贝文件1234567891011121314[root@Master base]# salt '192.168.111.45' cmd.run 'ls -l /root'192.168.111.45: total 8 -rw-------. 1 root root 1261 Jul 29 06:38 anaconda-ks.cfg -rw-r--r--. 1 apache apache 28 Jul 30 06:09 test[root@Master base]# salt '192.168.111.45' file.copy /root/test /root/test2192.168.111.45: True[root@Master base]# salt '192.168.111.45' cmd.run 'ls -l /root' 192.168.111.45: total 12 -rw-------. 1 root root 1261 Jul 29 06:38 anaconda-ks.cfg -rw-r--r--. 1 apache apache 28 Jul 30 06:09 test -rw-r--r--. 1 apache apache 28 Jul 30 06:27 test2 拷贝目录覆盖并拷贝目录，将会覆盖同名文件或目录 12345678910111213141516[root@Master base]# salt '192.168.111.45' cmd.run 'ls -l /root'192.168.111.45: total 12 -rw-------. 1 root root 1261 Jul 29 06:38 anaconda-ks.cfg -rw-r--r--. 1 apache apache 28 Jul 30 06:09 test -rw-r--r--. 1 apache apache 28 Jul 30 06:27 test2[root@Master base]# salt '192.168.111.45' file.copy /tmp /root/test3 recurse=True #192.168.111.45: True[root@Master base]# salt '192.168.111.45' cmd.run 'ls -l /root' 192.168.111.45: total 12 -rw-------. 1 root root 1261 Jul 29 06:38 anaconda-ks.cfg -rw-r--r--. 1 apache apache 28 Jul 30 06:09 test -rw-r--r--. 1 apache apache 28 Jul 30 06:27 test2 drwxrwxrwt. 9 root root 288 Jul 30 06:29 test3 file.directory_exists判断指定目录是否存在，存在则返回True，否则返回False 123[root@Master base]# salt '192.168.111.45' file.directory_exists /etc192.168.111.45: True file.diskusage递归计算指定路径的磁盘使用情况并以字节为单位返回 123456[root@Master base]# salt '192.168.111.45' file.diskusage /var192.168.111.45: 139618017[root@Master base]# salt '192.168.111.45' cmd.run 'du -sb /var'192.168.111.45: 139845541 /var file.file_exists1234567[root@Master base]# salt '192.168.111.45' file.file_exists /etc/passwd192.168.111.45: True[root@Master ~]# salt '192.168.111.45' file.file_exists /etc192.168.111.45: False因为/etc为目录而返回False。 file.find类似find命令并返回符合指定条件的路径列表The options include match criteria： name = path-glob # case sensitive iname = path-glob # case insensitive regex = path-regex # case sensitive iregex = path-regex # case insensitive type = file-types # match any listed type user = users # match any listed user group = groups # match any listed group size = [+-]number[size-unit] # default unit = byte mtime = interval # modified since date grep = regex # search file contentsand/or actions： delete [= file-types] # default type = &apos;f&apos; exec = command [arg ...] # where {} is replaced by pathname print [= print-opts]and/or depth criteria: maxdepth = maximum depth to transverse in path mindepth = minimum depth to transverse before checking files or directories The default action is print=pathpath-glob: * = match zero or more chars ? = match any char [abc] = match a, b, or c [!abc] or [^abc] = match anything except a, b, and c [x-y] = match chars x through y [!x-y] or [^x-y] = match anything except chars x through y {a,b,c} = match a or b or cpath-regex: a Python Regex (regular expression) pattern to match pathnames file-types: a string of one or more of the following: a: all file types b: block device c: character device d: directory p: FIFO (named pipe) f: plain file l: symlink s: socketusers: a space and/or comma separated list of user names and/or uids groups: a space and/or comma separated list of group names and/or gids size-unit: b: bytes k: kilobytes m: megabytes g: gigabytes t: terabytesinterval: [&lt;num&gt;w] [&lt;num&gt;d] [&lt;num&gt;h] [&lt;num&gt;m] [&lt;num&gt;s] where: w: week d: day h: hour m: minute s: secondprint-opts: a comma and/or space separated list of one or more of the following: group: group name md5: MD5 digest of file contents mode: file permissions (as integer) mtime: last modification time (as time_t) name: file basename path: file absolute path size: file size in bytes type: file type user: user name示例： 123salt '*' file.find / type=f name=\*.bak size=+10msalt '*' file.find /var mtime=+30d size=+10m print=path,size,mtimesalt '*' file.find /var/log name=\*.[0-9] mtime=+30d size=+10m delete file.get_gid获取指定文件的gid 123[root@Master ~]# salt '192.168.111.45' file.get_gid /root/test192.168.111.45: 48 file.get_group获取指定文件的组名 123456[root@Master ~]# salt '192.168.111.45' cmd.run 'ls -l /root/test'192.168.111.45: -rw-r--r--. 1 apache apache 28 Jul 30 06:09 /root/test[root@Master ~]# salt '192.168.111.45' file.get_group /root/test 192.168.111.45: apache file.get_hash获取指定文件的hash值，通过sha256算法计算 123456[root@Master ~]# salt '192.168.111.45' cmd.run 'sha256sum /root/test'192.168.111.45: 8c5846bb6d0f6c9fd071c3bc79a4b491fa73d219ba46b535ca70a9301bd6e4c9 /root/test[root@Master ~]# salt '192.168.111.45' file.get_hash /root/test192.168.111.45: 8c5846bb6d0f6c9fd071c3bc79a4b491fa73d219ba46b535ca70a9301bd6e4c9 file.get_mode获取文件权限，以数字方式显示 123[root@Master ~]# salt '192.168.111.45' file.get_mode /root/test192.168.111.45: 0644 file.get_sum按照指定的加密算法计算文件的编码值，默认使用sha256算法 md5 sha1 sha224 sha256 sha384 sha512123[root@Master ~]# salt '192.168.111.45' file.get_sum /root/test md5192.168.111.45: 32377745bcb853bd3556c29e95a24224 file.get_uid与file.get_user获取指定文件的uid或用户名 123456[root@Master ~]# salt '192.168.111.45' file.get_uid /root/test192.168.111.45: 48[root@Master ~]# salt '192.168.111.45' file.get_user /root/test192.168.111.45: apache file.gid_to_group将制定的gid转换为组名并显示 123[root@Master ~]# salt '192.168.111.45' file.gid_to_group 48192.168.111.45: apache file.group_to_gid将指定的组名转换为gid并显示 file.grep在指定文件中检索指定内容该函数支持通配符，若在指定的路径中用通配符则必须用双引号引起来 1234salt '*' file.grep /etc/passwd nobodysalt '*' file.grep /etc/sysconfig/network-scripts/ifcfg-eth0 ipaddr -- -isalt '*' file.grep /etc/sysconfig/network-scripts/ifcfg-eth0 ipaddr -- -i -B2salt '*' file.grep "/etc/sysconfig/network-scripts/*" ipaddr -- -i -l file.lsattr检查并显示出指定文件的属性信息 1[root@Master ~]# salt '192.168.111.45' file.lsattr /root/test file.mkdir创建目录并设置属主，属组及权限 12[root@Master ~]# salt '192.168.111.45' file.mkdir /root/test5[root@Master ~]# salt '*' file.mkdir /root/test6 tom tom 400 file.move移动或重命名 1234567[root@Master ~]# salt '192.168.111.45' file.move /root/test5 /root/test6192.168.111.45: ---------- comment: '/root/test5' moved to '/root/test6' result: True file.prepend把文件插入指定文件的开头 12345678910[root@Master ~]# salt '192.168.111.45' file.prepend /root/test '#!/bin/bash'192.168.111.45: Prepended 1 lines to "/root/test"[root@Master ~]# salt '192.168.111.45' cmd.run 'cat /root/test' 192.168.111.45: #!/bin/bash 123 hello world hayder lily file.sed修改文本的内容 12345678910111213141516[root@Master ~]# salt '192.168.111.45' file.sed /root/test 'hayder' 'Hayder'192.168.111.45: ---------- pid: 18760 retcode: 0 stderr: stdout:[root@Master ~]# salt '192.168.111.45' cmd.run 'cat /root/test' 192.168.111.45: #!/bin/bash 123 hello world Hayder lily file.read读取文件内容 1234567[root@Master ~]# salt '192.168.111.45' file.read /root/test192.168.111.45: #!/bin/bash 123 hello world Hayder lily file.readdir列出指定目录下的所有文件或目录，包括隐藏文件 123456789101112131415161718[root@Master ~]# salt '192.168.111.45' file.readdir /root192.168.111.45: - . - .. - .bash_logout - .bash_profile - .bashrc - .cshrc - .tcshrc - anaconda-ks.cfg - .pki - .viminfo - .bash_history - test2 - test3 - test6 - test.bak - test file.remove删除指定的文件或目录，若指定目录，则会递归删除 123[root@Master ~]# salt '192.168.111.45' file.remove /root/test6192.168.111.45: True file.rename重命名文件或目录 123[root@Master ~]# salt '192.168.111.45' file.rename /root/test3 /root/test10192.168.111.45: True file.set_mode给指定文件设置权限 123456[root@Master ~]# salt '192.168.111.45' file.set_mode /root/test10 0777192.168.111.45: 0777[root@Master ~]# salt '192.168.111.45' file.get_mode /root/test10192.168.111.45: 0777 file.symlink给指定的文件创建软连接 12345678[root@Master ~]# salt '192.168.111.45' file.symlink /root/test10 /opt/link192.168.111.45: True[root@Master ~]# salt '192.168.111.45' file.readdir /opt/192.168.111.45: - . - .. - link file.touch创建空文件或更新时间戳 123[root@Master ~]# salt '192.168.111.45' file.touch /opt/aa192.168.111.45: True file.write往一个指定文件里覆盖写入指定内容 123456789[root@Master ~]# salt '192.168.111.45' file.write /opt/aa "hayder"192.168.111.45: Wrote 1 lines to "/opt/aa"[root@Master ~]# salt '192.168.111.45' file.write /opt/aa "lily" 192.168.111.45: Wrote 1 lines to "/opt/aa"[root@Master ~]# salt '192.168.111.45' file.read /opt/aa192.168.111.45: lily SaltStack之return与job管理SaltStack组件之returnreturn组件可以理解为SaltStack系统对执行Minion返回后的数据进行存储或者返回给其他程序，它支持多种存储方式，比如Mysql，Mongodb，Redis,Memcache，ES等，通过return我们可以对SaltStack的每次操作进行记录，对以后日志审计提供了数据来源。也支持自定义return，由python来编写。在选择和配置好要使用的return后，只需要在salt命令后指定return即可。 return流程return是在Master端触发任务，然后Minion接受处理任务后直接与return存储服务器建立连接，然后把数据return到存储服务器上。关于这点一定要注意，因为此过程都是Minion端操作存储服务器，所以要确保Minion端的配置跟依赖包是正确的，这意味着我们将必须在每个Minion上安装指定的return方式依赖包，加入使用Mysql作为return存储方式，那么我们将在每台Minion上安装python-mysql模块。 使用mysql作为return存储方式在所有的Minion安装MySQL-python模块1234567[root@Master ~]# salt '*' pkg.install MySQL-python[root@Master ~]# salt '*' cmd.run 'rpm -qa |grep MySQL-python'192.168.111.43: MySQL-python-1.2.5-1.el7.x86_64192.168.111.45: MySQL-python-1.2.5-1.el7.x86_64 部署一台mysql服务器用作存储服务器（在192.168.111.45机器）123[root@minion ~]# yum -y install mariadb-server[root@minion ~]# systemctl start mariadb[root@minion ~]# systemctl enable mariadb 创建表结构 123CREATE DATABASE saltDEFAULT CHARACTER SET utf8DEFAULT COLLATE utf8_general_ci; 1USE salt; 123456DROP TABLE IF EXISTS jids;CREATE TABLE `jids` (`jid` varchar(255) NOT NULL,`load` mediumtext NOT NULL,UNIQUE KEY `jid` (`jid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 12345678910111213DROP TABLE IF EXISTS salt_returns;CREATE TABLE `salt_returns` (`fun` varchar(50) NOT NULL,`jid` varchar(255) NOT NULL,`return` mediumtext NOT NULL,`id` varchar(255) NOT NULL,`success` varchar(10) NOT NULL,`full_ret` mediumtext NOT NULL,`alter_time` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,KEY `id` (`id`),KEY `jid` (`jid`),KEY `fun` (`fun`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 123456789DROP TABLE IF EXISTS salt_events;CREATE TABLE `salt_events` (`id` BIGINT NOT NULL AUTO_INCREMENT,`tag` varchar(255) NOT NULL,`data` varchar(1024) NOT NULL,`alter_time` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,PRIMARY KEY (`id`),KEY `tag` (`tag`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; mysql授权： 12MariaDB [salt]&gt; grant all on salt.* to salt@'%' identified by 'salt';MariaDB [salt]&gt; flush privileges; 配置Minion1234567vim /etc/salt/minion添加：mysql.host: '192.168.111.45'mysql.user: 'salt'mysql.pass: 'salt'mysql.db: 'salt'mysql.port: 3306 Master上执行命令测试12345[root@Master ~]# salt '*' test.ping --return mysql 192.168.111.43: True192.168.111.45: True 12345678910111213141516171819202122232425262728MariaDB [salt]&gt; select * from salt_returns\G;*************************** 1. row *************************** fun: test.ping jid: 20190801213931822721 return: true id: 192.168.111.43 success: 1 full_ret: &#123;"fun_args": [], "jid": "20190801213931822721", "return": true, "retcode": 0, "success": true, "fun": "test.ping", "id": "192.168.111.43"&#125;alter_time: 2019-08-01 21:39:32*************************** 2. row *************************** fun: test.ping jid: 20190801214408253510 return: true id: 192.168.111.43 success: 1 full_ret: &#123;"fun_args": [], "jid": "20190801214408253510", "return": true, "retcode": 0, "success": true, "fun": "test.ping", "id": "192.168.111.43"&#125;alter_time: 2019-08-01 21:44:08*************************** 3. row *************************** fun: test.ping jid: 20190801214408253510 return: true id: 192.168.111.45 success: 1 full_ret: &#123;"fun_args": [], "jid": "20190801214408253510", "return": true, "retcode": 0, "success": true, "fun": "test.ping", "id": "192.168.111.45"&#125;alter_time: 2019-08-01 21:44:083 rows in set (0.00 sec)ERROR: No query specified job cachejob cache流程return时是由Minion直接与存储数据库进行交互，因此需要在每台Minion上安装指定的存储方式的模块，比如python-mysql，job cache当Minion把结果返回给Master后，由master将结果缓存在本地，然后将缓存的结果存储到指定的存储服务器，比如mysql。 开启master端的master_job_cache12345678[root@Master ~]# vim /etc/salt/master....此处省略N行master_job_cache: mysqlmysql.host: '192.168.111.45'mysql.user: 'salt'mysql.pass: 'salt'mysql.db: 'salt'mysql.port: 3306 测试是否存储到数据库12345678910111213141516171819[root@Master ~]# salt '*' cmd.run 'df -h'192.168.111.45: Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 14G 1.4G 13G 11% / devtmpfs 485M 0 485M 0% /dev tmpfs 497M 12K 496M 1% /dev/shm tmpfs 497M 7.1M 489M 2% /run tmpfs 497M 0 497M 0% /sys/fs/cgroup /dev/sda1 1014M 130M 885M 13% /boot tmpfs 100M 0 100M 0% /run/user/0192.168.111.43: Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 14G 1.3G 13G 10% / devtmpfs 485M 0 485M 0% /dev tmpfs 497M 28K 496M 1% /dev/shm tmpfs 497M 7.1M 489M 2% /run tmpfs 497M 0 497M 0% /sys/fs/cgroup /dev/sda1 1014M 130M 885M 13% /boot tmpfs 100M 0 100M 0% /run/user/0 1234567891011121314151617181920MariaDB [salt]&gt; select * from salt_returns\G;*************************** 1. row *************************** fun: cmd.run jid: 20190801220129134207 return: "Filesystem Size Used Avail Use% Mounted on\n/dev/mapper/centos-root 14G 1.4G 13G 11% /\ndevtmpfs 485M 0 485M 0% /dev\ntmpfs 497M 12K 496M 1% /dev/shm\ntmpfs 497M 7.1M 489M 2% /run\ntmpfs 497M 0 497M 0% /sys/fs/cgroup\n/dev/sda1 1014M 130M 885M 13% /boot\ntmpfs 100M 0 100M 0% /run/user/0" id: 192.168.111.45 success: 1 full_ret: &#123;"fun_args": ["df -h"], "jid": "20190801220129134207", "return": "Filesystem Size Used Avail Use% Mounted on\n/dev/mapper/centos-root 14G 1.4G 13G 11% /\ndevtmpfs 485M 0 485M 0% /dev\ntmpfs 497M 12K 496M 1% /dev/shm\ntmpfs 497M 7.1M 489M 2% /run\ntmpfs 497M 0 497M 0% /sys/fs/cgroup\n/dev/sda1 1014M 130M 885M 13% /boot\ntmpfs 100M 0 100M 0% /run/user/0", "retcode": 0, "success": true, "cmd": "_return", "_stamp": "2019-08-02T02:01:29.197235", "fun": "cmd.run", "id": "192.168.111.45"&#125;alter_time: 2019-08-01 22:01:29*************************** 2. row *************************** fun: cmd.run jid: 20190801220129134207 return: "Filesystem Size Used Avail Use% Mounted on\n/dev/mapper/centos-root 14G 1.3G 13G 10% /\ndevtmpfs 485M 0 485M 0% /dev\ntmpfs 497M 28K 496M 1% /dev/shm\ntmpfs 497M 7.1M 489M 2% /run\ntmpfs 497M 0 497M 0% /sys/fs/cgroup\n/dev/sda1 1014M 130M 885M 13% /boot\ntmpfs 100M 0 100M 0% /run/user/0" id: 192.168.111.43 success: 1 full_ret: &#123;"fun_args": ["df -h"], "jid": "20190801220129134207", "return": "Filesystem Size Used Avail Use% Mounted on\n/dev/mapper/centos-root 14G 1.3G 13G 10% /\ndevtmpfs 485M 0 485M 0% /dev\ntmpfs 497M 28K 496M 1% /dev/shm\ntmpfs 497M 7.1M 489M 2% /run\ntmpfs 497M 0 497M 0% /sys/fs/cgroup\n/dev/sda1 1014M 130M 885M 13% /boot\ntmpfs 100M 0 100M 0% /run/user/0", "retcode": 0, "success": true, "cmd": "_return", "_stamp": "2019-08-02T02:01:29.224620", "fun": "cmd.run", "id": "192.168.111.43"&#125;alter_time: 2019-08-01 22:01:292 rows in set (0.00 sec)ERROR: No query specified job管理获取任务jid 12345执行命令时-v[root@Master ~]# salt '*' cmd.run 'uptime' -vExecuting job with jid 20190801220408625641xxxxxxxxxxxx 通过jid获取此任务的返回结果 12345[root@Master ~]# salt-run jobs.lookup_jid 20190801220408625641192.168.111.43: 22:04:08 up 3 days, 22:56, 2 users, load average: 0.13, 0.37, 0.22192.168.111.45: 22:04:08 up 3 days, 22:56, 2 users, load average: 0.00, 0.01, 0.05 SaltStack之salt-sshsalt-ssh介绍salt-ssh可以让我们不需要在受控机上安装salt-minion客户端也能实现管理操作。 salt-ssh的特点 远程系统需要python支持，除非使用-r选项发送原始的ssh命令 salt-ssh是一个软件包，需要安装之后才能使用，命令本身也是salt-ssh salt-ssh不会取代标准的salt通信系统，它只是提供可一个基于ssh的代替方案，不需要ZeroMQ和agent。 由于所有与Salt SSH的通信都是通过ssh执行的，所以它比使用ZeroMQ的标准要慢的多。 salt-ssh远程管理的方式salt-ssh有两种方式实现远程管理，一种是在配置文件中记录所有客户端的信息，如ip，端口，用户名，密码以及sudo等，另一种是使用密钥实现远程管理，不需要输入密码。 salt-ssh管理在master上安装salt-ssh 1[root@Master ~]# yum -y install salt-ssh 通过使用用户名密码的SSH实现远程管理修改配置文件，添加受控机信息 123456[root@Master ~]# vim /etc/salt/roster....此处省略N行vm: host: 192.168.111.45 user: root passwd: abc#123 测试连通性[root@Master ~]# salt-ssh ‘*’ test.ping 123456789101112[ERROR ] Failed collecting tops for Python binary python3.vm: ---------- retcode: 254 stderr: stdout: The host key needs to be accepted, to auto accept run salt-ssh with the -i flag: The authenticity of host '192.168.111.45 (192.168.111.45)' can't be established. ECDSA key fingerprint is SHA256:6BNxgEuRY3DPSw59vl/2Iq9DUcwGk3nXHjNm1O6gzhM. ECDSA key fingerprint is MD5:97:6b:3e:cf:85:c2:81:14:44:21:ba:b9:58:ae:0a:d7. Are you sure you want to continue connecting (yes/no)? 从上面信息看出，第一次访问时需要输入yes/no，但是saltstack不支持交互式操作的，所以需要添加-i参数，让系统自动接受验证。 123[root@Master ~]# salt-ssh -i '*' test.pingvm: True 通过salt-ssh初始化系统安装salt-minion安装salt-ssh修改roster配置文件，添加受控主机执行状态命令，初始化系统，安装salt-minion。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@Master ~]# mkdir -p /srv/salt/base/&#123;repo,files&#125;[root@Master ~]# \cp /etc/yum.repos.d/salt-latest.repo /srv/salt/base/repo/salt-latest.repo[root@Master ~]# cp /etc/salt/minion /srv/salt/base/files/[root@Master salt]# tree base/base/├── files│ └── minion├── minion.sls├── repo│ └── salt-latest.repo└── repo.sls2 directories, 4 files[root@Master ~]# vim /srv/salt/base/repo.slssalt-repo: file.managed: - name: /etc/yum.repos.d/salt-latest.repo - source: salt://repo/salt-latest.repo - user: root - group: root - mode: 644[root@Master ~]# vim /srv/salt/base/minion.slssalt-minion-install: pkg.installed: - name: salt-minionsalt-minion-conf: file.managed: - name: /etc/salt/minion - source: salt://files/minion - user: root - group: root - mode: 644 - template: jinja - default: ID: &#123;&#123; grains['ipv4'] [1] &#125;&#125; - require: - pkg: salt-minion-installsalt-minion-service: service.running: - name: salt-minion - enable: True - start: True - watch: - file: /etc/salt/minion salt-syndic分布式架构salt-syndic架构图 salt-syndic的优劣势优势： 可以通过syndic实现更复杂的salt架构 减轻master的负担 劣势： syndic的/srv目录下的salt和pillar目录内容要与最顶层的master下的一致，所以要进行数据同步，同步方案通salt-master高可用。 最顶层的master不知道自己有几个syndic，它只知道自己有多少个minion，并不知道这些minion是由哪些syndic来管理的。 在下发到syndic过程中，如果网络出现抖动，导致没有收到消息或者延迟收到，master并无感知，最终会导致整个任务的返回不完整。 salt-syndic部署]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
        <tag>saltstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1hexo new "My New Post" More info: Writing Run server1hexo server More info: Server Generate static files1hexo generate More info: Generating Deploy to remote sites1hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python装饰器详解]]></title>
    <url>%2F2013%2F07%2F13%2FPython%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[在函数里定义函数在Python函数里定义另一个函数 123456789101112131415161718192021222324def hi(name="hayder"): print("now you are inside the hi() function") def greet(): return "now you are in the greet() function" def welcome(): return "now you are in the welcome() function" print(greet()) print(welcome()) print("now you are back in the hi() function")hi()#output:now you are inside the hi() function# now you are in the greet() function# now you are in the welcome() function# now you are back in the hi() function# 上面展示了无论何时你调用hi(), greet()和welcome()将会同时被调用。# 然后greet()和welcome()函数在hi()函数之外是不能访问的，比如：greet()#outputs: NameError: name 'greet' is not defined 那现在我们知道了再函数中是可以定义另外的函数，也就是说，我们可以创建嵌套的函数，下一步，就是需要理解函数也能返回函数。 从函数中返回函数其实并不需要在一个函数里去执行另一个函数，我们可以将其作为输出返回出来： 123456789101112131415161718192021def hi(name="hayder"): def greet(): return "now you are in the greet() function" def welcome(): return "now you are in the welcome() function" if name == "hayder": return greet else: return welcomea = hi()print(a)#outputs: &lt;function greet at 0x7f2143c01500&gt;#上面清晰地展示了`a`现在指向到hi()函数中的greet()函数#现在试试这个print(a())#outputs: now you are in the greet() function 注意，if/else语句中返回的是greet和welcome，而不是greet()和welcome()。因为当加上()时，这个函数就会执行，不加()时可以被到处传递，并且可以赋值给别的变量而不去执行它。 将函数作为参数传给另一个函数12345678910def hi(): return "hi hayder!"def doSomethingBeforeHi(func): print("I am doing some boring work before executing hi()") print(func())doSomethingBeforeHi(hi)#outputs:I am doing some boring work before executing hi()# hi hayder! 接下来要学习装饰器真正是什么了，装饰器让你在一个函数的前后去执行代码。 下面是一个装饰器的例子123456789101112131415161718192021222324def a_new_decorator(a_func): def wrapTheFunction(): print("I am doing some boring work before executing a_func()") a_func() print("I am doing some boring work after executing a_func()") return wrapTheFunctiondef a_function_requiring_decoration(): print("I am the function which needs some decoration to remove my foul smell")a_function_requiring_decoration()#outputs: "I am the function which needs some decoration to remove my foul smell"a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration)#now a_function_requiring_decoration is wrapped by wrapTheFunction()a_function_requiring_decoration()#outputs:I am doing some boring work before executing a_func()# I am the function which needs some decoration to remove my foul smell# I am doing some boring work after executing a_func() 将a_function_requiring_decoration函数当成一个参数传递给a_new_decorator函数并返回wrapTheFunction函数上面的例子也可以用@语法糖来表示： 1234@a_new_decoratordef a_function_requiring_decoration(): print("I am the function which needs some decoration to remove my foul smell")a_function_requiring_decoration() 上面的例子会存在一个问题，如果我们运行以下代码就会发现： 12print(a_function_requiring_decoration.__name__)# Output: wrapTheFunction 这个结果并不是我们想要的，我们需要的输出应该是a_function_requiring_decoration,这里的函数被wrapTheFunction替代了，它重写了我们函数的名字和注释文档。我们可以使用functools.wraps来解决。 123456789101112131415161718from functools import wrapsdef a_new_decorator(a_func): @wraps(a_func) def wrapTheFunction(): print("I am doing some boring work before executing a_func()") a_func() print("I am doing some boring work after executing a_func()") return wrapTheFunction@a_new_decoratordef a_function_requiring_decoration(): """Hey yo! Decorate me!""" print("I am the function which needs some decoration to " "remove my foul smell")print(a_function_requiring_decoration.__name__)# Output: a_function_requiring_decoration 下面是另一个例子： 1234567891011121314151617181920from functools import wrapsdef decorator_name(f): @wraps(f) def decorated(*args, **kwargs): if not can_run: return "Function will not run" return f(*args, **kwargs) return decorated@decorator_namedef func(): return("Function is running")can_run = Trueprint(func())# Output: Function is runningcan_run = Falseprint(func())# Output: Function will not run @wrap接受一个函数来进行装饰，并加入了复制函数名称、注释文档、参数列表等功能，可以让我们在装饰器里面访问在装饰之前的函数的属性。 使用场景下面几个例子可以体现装饰器在让一些事情管理起来更简单。 授权装饰器能有助于检查某个人是否被授权去使用一个web应用的端点，它们被大量使用与flask和django。 12345678910from functools import wrapsdef requires_auth(f): @wraps(f) def decorated(*args, **kwargs): auth = request.authorization if not auth or not check_auth(auth.username, auth.password): authenticate() return f(*args, **kwargs) return decorated 日志1234567891011121314151617from functools import wrapsdef logit(func): @wraps(func) def with_logging(*args, **kwargs): print(func.__name__ + " was called") return func(*args, **kwargs) return with_logging@logitdef addition_func(x): """Do some math.""" return x + xresult = addition_func(4)# Output: addition_func was called 重试12345678910111213141516171819202122232425262728def retry(count=1): def dec(f): def ff(*args, **kwargs): ex = None for i in range(count): try: ans = f(*args, **kwargs) return ans except Exception as e: ex = e raise ex return ff return decdb = []@retry(count=10)def until_six(): db.append("haha") print("until_six") return db[6]print(until_six()) 带参数的装饰器来想想这个问题，难道@wraps不也是个装饰器吗？但是，它接收一个参数，就像任何普通的函数能做的那样。那么，为什么我们不也那样做呢？这是因为，当你使用@my_decorator语法时，你是在应用一个以单个函数作为参数的一个包裹函数。记住，Python里每个东西都是一个对象，而且这包括函数！记住了这些，我们可以编写一下能返回一个包裹函数的函数。仍然是上面的日志例子，我们加以修改 12345678910111213141516171819202122232425262728293031from functools import wrapsdef logit(logfile='out.log'): def logging_decorator(func): @wraps(func) def wrapped_function(*args, **kwargs): log_string = func.__name__ + " was called" print(log_string) # 打开logfile，并写入内容 with open(logfile, 'a') as opened_file: # 现在将日志打到指定的logfile opened_file.write(log_string + '\n') return func(*args, **kwargs) return wrapped_function return logging_decorator@logit()def myfunc1(): passmyfunc1()# Output: myfunc1 was called# 现在一个叫做 out.log 的文件出现了，里面的内容就是上面的字符串@logit(logfile='func2.log')def myfunc2(): passmyfunc2()# Output: myfunc2 was called# 现在一个叫做 func2.log 的文件出现了，里面的内容就是上面的字符串 类装饰器现在我们有了能用于正式环境的logit装饰器，但是当我们的应用的某些部分还比较脆弱的时候，异常也许是需要更紧急关注的事情。比如有时只想打印日志到一个文件，有时想把引起你注意的问题发送到邮件，同时也保留日志。这时我们需要一个类而不是一个函数的来构建装饰器。 123456789101112131415161718192021222324252627from functools import wrapsclass logit(object): def __init__(self, logfile='out.log'): self.logfile = logfile def __call__(self, func): @wraps(func) def wrapped_function(*args, **kwargs): log_string = func.__name__ + " was called" print(log_string) # 打开logfile并写入 with open(self.logfile, 'a') as opened_file: # 现在将日志打到指定的文件 opened_file.write(log_string + '\n') # 现在，发送一个通知 self.notify() return func(*args, **kwargs) return wrapped_function def notify(self): # logit只打日志，不做别的 pass @logit()def myfunc1(): pass 现在我们给logit创建子类，来添加email功能,使只打印日志和即打印日志又发送邮件的装饰器分开。 123456789101112class email_logit(logit): ''' 一个logit的实现版本，可以在函数调用时发送email给管理员 ''' def __init__(self, email='admin@myproject.com', *args, **kwargs): self.email = email super(email_logit, self).__init__(*args, **kwargs) def notify(self): # 发送一封email到self.email # 这里就不做实现了 pass 这样@email_logit会在@logit装饰器打印日志的基础上增加了发送邮件的功能。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
</search>
